{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook experiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_community.document_loaders.parsers import RapidOCRBlobParser\n",
    "from langchain_community.document_loaders.parsers import TesseractBlobParser\n",
    "from langchain_community.document_loaders.parsers.images import BaseImageBlobParser\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import pymupdf4llm\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.schema import Document\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyMuPDFLoader(file_path = \"/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf\",\n",
    "                       mode=\"single\",\n",
    "                       extract_images = True,\n",
    "                       images_parser =RapidOCRBlobParser(),\n",
    "                       images_inner_format = \"html-img\",\n",
    "                       extract_tables = 'markdown',\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-4 vs. Human Translators: A Comprehensive Evaluation of\n",
      "Translation Quality Across Languages, Domains, and Expertise Levels\n",
      "Jianhao Yan1,2∗\n",
      "Pingchuan Yan3∗\n",
      "Yulong Chen4∗\n",
      "Judy Li5\n",
      "Xianchao Zhu5\n",
      "Yue Zhang2,6,\u00001 Zhejiang University\n",
      "2 School of Engineering, Westlake University\n",
      "3 University College London\n",
      "4 University of Cambridge\n",
      "5 Lan-Bridge Group\n",
      "6 Institute of Advanced Technology, Westlake Institute for Advanced Study\n",
      "elliottyan37@gmail.com\n",
      "Abstract\n",
      "This study comprehensively evaluates the\n",
      "translation quality of Large Language Mod-\n",
      "els (LLMs), specifically GPT-4, against hu-\n",
      "man translators of varying expertise lev-\n",
      "els across multiple language pairs and do-\n",
      "mains. Through carefully designed annota-\n",
      "tion rounds, we find that GPT-4 performs\n",
      "comparably to junior translators in terms of\n",
      "total errors made but lags behind medium\n",
      "and senior translators. We also observe the\n",
      "imbalanced performance across different lan-\n",
      "guages and domains, with GPT-4’s transla-\n",
      "tion capability gradually weakening from\n",
      "resource-rich to resource-poor directions. In\n",
      "addition, we qualitatively study the trans-\n",
      "lation given by GPT-4 and human transla-\n",
      "tors, and find that GPT-4 translator suffers\n",
      "from literal translations, but human trans-\n",
      "lators sometimes overthink the background\n",
      "information. To our knowledge, this study\n",
      "is the first to evaluate LLMs against human\n",
      "translators and analyze the systematic differ-\n",
      "ences between their outputs, providing valu-\n",
      "able insights into the current state of LLM-\n",
      "based translation and its potential limitations.\n",
      "1\n",
      "Introduction\n",
      "Recent studies show that LLMs can serve as a\n",
      "strong translation system and a good substitute for\n",
      "NMT models (Jiao et al., 2023a; Wang et al., 2023a;\n",
      "Enis and Hopkins, 2024; Huang et al., 2023; Wu\n",
      "et al., 2024a; Hendy et al., 2023; Peng et al., 2023).\n",
      "For example, Jiao et al. (2023a) and Wang et al.\n",
      "(2023a) find that GPT-4 can outperform commer-\n",
      "cial machine translation systems via automatic and\n",
      "human evaluations. Such impressive results have\n",
      "hastened a wide range of applications, including\n",
      "the use of GPT-4 for literary translation (Wu et al.,\n",
      "2024b).\n",
      "∗These authors contributed equally to this work.\n",
      "Despite their impressive capabilities, the nature\n",
      "of LLM output compared to human translators\n",
      "remains unclear.\n",
      "This raises two critical ques-\n",
      "tions: (1) How do LLMs compare to human ex-\n",
      "perts in translation quality? and (2) Are there\n",
      "fundamental differences in their outputs? These\n",
      "inquiries are particularly relevant in light of recent\n",
      "research demonstrating significant distinctions be-\n",
      "tween LLM-generated and human-generated texts\n",
      "in general (Li et al., 2023; Bao et al., 2023). Such\n",
      "findings suggest that even if LLMs produce high-\n",
      "quality translations, their outputs may possess\n",
      "unique characteristics that distinguish them from\n",
      "human-produced translations.\n",
      "To determine where LLMs fall within the spec-\n",
      "trum of human translation proficiency, which\n",
      "ranges from novice translators to seasoned profes-\n",
      "sionals, we study the problem by taking the current\n",
      "representative LLM, i.e., GPT-4, and comparing\n",
      "it against human translators with different exper-\n",
      "tise. We first conduct a preliminary study compar-\n",
      "ing human translations against GPT-4 translations,\n",
      "finding that even experts cannot reach a consen-\n",
      "sus on which translation is better. Given these\n",
      "findings, we take a finer-grained evaluation across\n",
      "different languages and domains, so that translation\n",
      "quality can be better calibrated and systematic dif-\n",
      "ferences can be measured. Our evaluation covers\n",
      "three language pairs from resource-rich to resource-\n",
      "poor, i.e., Chinese↔English, Russian↔English,\n",
      "and Chinese↔Hindi, and three domains, i.e., News,\n",
      "Technology, and Biomedical. Given a source sen-\n",
      "tence, we ask junior, medium, and senior trans-\n",
      "lators and GPT-4 to generate the corresponding\n",
      "translation in the target language. Then given each\n",
      "translation pair, we hire independent expert annota-\n",
      "tors to label the errors in the target sentence under\n",
      "the MQM schema (Freitag et al., 2021). We find\n",
      "that GPT-4 reaches a comparable performance to\n",
      "junior translators in the perspective of total errors\n",
      "made, and lags behind senior ones with a consider-\n",
      "arXiv:2407.03658v1  [cs.CL]  4 Jul 2024\n",
      "\fable gap.\n",
      "Our further analyses and qualitative studies show\n",
      "that there are imbalanced performances for differ-\n",
      "ent languages and domains. From resource-rich to\n",
      "resource-poor directions, GPT-4’s translation capa-\n",
      "bility gradually weakens. For resource-rich direc-\n",
      "tions like Chinese↔English, GPT-4 performs com-\n",
      "parably with junior translators and even close to\n",
      "medium translators, but in Chinese↔Hindi, it even\n",
      "lags behind our baseline system. The weaknesses\n",
      "mentioned above are also general shortcomings of\n",
      "large models and reflect that although large models\n",
      "have achieved universal translation with a focus\n",
      "on one language, translation between low-resource\n",
      "languages remains a relative weakness.\n",
      "To our knowledge, we are the first to evaluate\n",
      "LLMs against human translators and analyze the\n",
      "systematic differences between LLMs and human\n",
      "translators.\n",
      "2\n",
      "Related Work\n",
      "Benchmarking LLMs\n",
      "Previous studies have\n",
      "benchmarked LLMs on various NLP tasks. Xu et al.\n",
      "(2020) benchmark several LLMs on Chinese text,\n",
      "evaluating their Chinese ability. Ye et al. (2024)\n",
      "assess LLMs through Question Answering (QA),\n",
      "MMLU (Hendrycks et al., 2021), and other metrics.\n",
      "From these tests, LLMs with larger scales are gen-\n",
      "erally proved to be more accurate except for certain\n",
      "tasks. Yuan et al. (2023) demonstrates that LLMs\n",
      "perform well in long-context understanding and\n",
      "are more capable with Out-of-Distribution, which\n",
      "means LLMs have a certain degree of generaliza-\n",
      "tion ability.\n",
      "Further to the MT field, Jiao et al. (2023b) find\n",
      "that GPT-4 performed competitively with other\n",
      "SotA translation products. Wang et al. (2023a)\n",
      "further investigated the capability of GPT-4 in\n",
      "document-level translation, the results show that\n",
      "GPT-4 performs better than commercial translation\n",
      "products and document NMT methods. Compared\n",
      "to them, our work empirically shows that GPT-4 is\n",
      "comparable to junior human translators.\n",
      "LLMs as Human Experts\n",
      "Due to the great ca-\n",
      "pacities of GPT-4 over traditional NLP models,\n",
      "researchers have investigated and compared the\n",
      "performance of GPT-4 as human experts in mul-\n",
      "tiple NLP tasks. Zhu et al. (2024) highlight that\n",
      "GPT-4 and GPT-4-turbo show top performance on\n",
      "a Chinese financial language understanding task.\n",
      "Liu et al. (2023b) find the LLMs can be benefi-\n",
      "cial to biomedical NLP tasks. Goyal et al. (2022)\n",
      "compare GPT models with several summarization\n",
      "models and humans, and find that GPT can gen-\n",
      "erate summaries preferred by humans. In AI for\n",
      "education area, Nguyen and Allan (2024) show\n",
      "GPT-4’s can provide teaching feedback for stu-\n",
      "dents. Maloney et al. (2024) find that GPT-4 shows\n",
      "close performance compared with human partici-\n",
      "pants in coordination games. Siu (2023) show that\n",
      "GPT-4 is comparable to humans on technical trans-\n",
      "lation tasks. Bojic et al. (2023) find that GPT-4 can\n",
      "outperform human experts on linguistic pragmatic\n",
      "tasks. In clinical diagnostics, Han et al. (2023)\n",
      "find that GPT-4 can give comparable performance\n",
      "to humans, and GPT-4v (vision version) can even\n",
      "outperform human experts.\n",
      "Human Evaluation for MT\n",
      "(Graham et al.,\n",
      "2013) first propose Direct Assessment (DA), which\n",
      "uses a continuous score from 0 to 100 to repre-\n",
      "sent the quality of a hypothesis. DA has been\n",
      "adopted in WMT translation tasks for the past\n",
      "few years (Farhad et al., 2021; Kocmi et al., 2022,\n",
      "2023). MQM (Lommel et al., 2014), the annota-\n",
      "tion used in this paper, is another widely used an-\n",
      "notation scheme (Klubiˇcka et al., 2018; Rei et al.,\n",
      "2020a). It requires the annotators to annotate the\n",
      "error span for each hypothesis and is shown to be\n",
      "more accurate and reliable than DA (Freitag et al.,\n",
      "2021). Thus, it is utilized in the metrics tasks of\n",
      "2022 and 2023 WMT challenges (Freitag et al.,\n",
      "2022, 2023).\n",
      "Human Parity\n",
      "The human parity for machine\n",
      "translation systems is first claimed by (Hassan et al.,\n",
      "2018), which describes a comparable performance\n",
      "on the WMT 2017 news translation task from Chi-\n",
      "nese to English when compared to professional hu-\n",
      "man translations. However, this claim is challenged\n",
      "by the following research, raising concerns about\n",
      "the limited scope of human parity. These limita-\n",
      "tions include the expertise of human evaluators (Fis-\n",
      "cher and L¨\"aubli, 2020), the origin and quality of\n",
      "source sentences (Toral et al., 2018; Kim et al.,\n",
      "2023), the limited scenario of comparison (Poibeau,\n",
      "2022) and difficulty of translation (Graham et al.,\n",
      "2020), indicating significant gaps between NMT\n",
      "models and the professional translators. In this\n",
      "work, we evaluate whether the SOTA LLM GPT-\n",
      "4 performs comparable to professional translators\n",
      "and what differs between human translators and\n",
      "LLMs. With the above lessons in mind, we address\n",
      "\fthese limitations by hiring expert annotators, avoid-\n",
      "ing target-origin source text, manually evaluating\n",
      "source sentences, and covering high-resource to\n",
      "low-resource language pairs and various domains.\n",
      "3\n",
      "Preliminary Study\n",
      "This section presents our preliminary study. We\n",
      "aim to first compare GPT-4 translations with hu-\n",
      "man translations qualitatively, in a coarse manner.\n",
      "Our comparison is simple and direct. We sample\n",
      "human-translated texts and prompt GPT-4 to trans-\n",
      "late the same source sentence. Then, we ask expert\n",
      "annotators to determine which translation is better.\n",
      "Particularly, to have a quick overview of the qual-\n",
      "ities of human translations against GPT-4 transla-\n",
      "tions, we first utilize COMET-QE1 to score our\n",
      "in-house Chinese to English human-translated doc-\n",
      "uments, and select two documents with the highest\n",
      "score and the lowest score. Note that our in-house\n",
      "translated documents are all translated by profes-\n",
      "sional translators. In this way, we gather 40 pairs\n",
      "of translations from professional translators and\n",
      "GPT-4, respectively. Recent findings (Freitag et al.,\n",
      "2021) have demonstrated that crowd-sourced hu-\n",
      "man ratings are less reliable for high-quality MT\n",
      "evaluation. Thus, we hire six expert annotators to\n",
      "compare the two translations and select the better\n",
      "translations they find. We randomly shuffle the\n",
      "GPT-4 and human translations to prevent annota-\n",
      "tors from identifying GPT-4.\n",
      "The\n",
      "average\n",
      "win\n",
      "rate\n",
      "of\n",
      "GPT\n",
      "is\n",
      "15.5/40 (36.25%).\n",
      "It looks like a clear win\n",
      "for human translators, but when delving deeper,\n",
      "we find that the expert annotators have a low\n",
      "ratio of agreement with each other. In Table 1,\n",
      "most annotators only agree with each other at\n",
      "around 60% (the baseline is 50%) of an agreed\n",
      "winner at each source sentence.\n",
      "We further\n",
      "conduct a significance test and only annotator\n",
      "B finds human translation significantly better\n",
      "than GPT’s translation and other annotators\n",
      "have high p-values. Given annotators’ expertise\n",
      "and our task is straightforward, these results\n",
      "indicate that even expert annotators find it difficult\n",
      "to agree on which translation is better, and\n",
      "GPT-generated translations might have different\n",
      "advantages against human-generated ones. These\n",
      "results motivate us to conduct a finer-grained and\n",
      "comprehensive evaluation to reveal the systematic\n",
      "difference between GPT-4 and human translations.\n",
      "1Unbabel/wmt23-cometkiwi-da-xl\n",
      "Annotators\n",
      "A\n",
      "B\n",
      "C\n",
      "D\n",
      "E\n",
      "F\n",
      "A\n",
      "100.0\n",
      "57.5\n",
      "65.0\n",
      "65.0\n",
      "62.5\n",
      "67.5\n",
      "B\n",
      "-\n",
      "100.0\n",
      "52.5\n",
      "52.5\n",
      "50.0\n",
      "50.0\n",
      "C\n",
      "-\n",
      "-\n",
      "100.0\n",
      "65.0\n",
      "82.5\n",
      "67.5\n",
      "D\n",
      "-\n",
      "-\n",
      "-\n",
      "100.0\n",
      "57.5\n",
      "62.5\n",
      "E\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "100.0\n",
      "70.0\n",
      "F\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "100.0\n",
      "p-value\n",
      "1.000\n",
      "0.038\n",
      "0.268\n",
      "0.081\n",
      "0.154\n",
      "0.875\n",
      "Table 1: Ratio(%) of agreed winner across expert\n",
      "annotators and significance p-value for binomial\n",
      "test. P-value < 0.05 denotes a significant difference\n",
      "between GPT-4 and Human.\n",
      "4\n",
      "Main Experimental Setup\n",
      "Motivated by the results from our preliminary\n",
      "study, we conduct a comprehensive and fine-\n",
      "grained evaluation, for revealing the systematic\n",
      "difference between humans and GPTs. Specifically,\n",
      "we employed the widely recognized Multidimen-\n",
      "sional Quality Metrics (MQM) framework (Lom-\n",
      "mel et al., 2014) and compared human translators\n",
      "with varying levels of expertise to GPT-4. Our\n",
      "evaluation spans multiple languages and domains,\n",
      "aiming to furnish broad insights into these compar-\n",
      "isons.\n",
      "4.1\n",
      "Data Collection\n",
      "We collect multilingual and multi-domain source\n",
      "sentences. Our multilingual evaluation data con-\n",
      "tains six language directions, covering high re-\n",
      "source to low resource, including English to Chi-\n",
      "nese, Chinese to English, English to Russian, Rus-\n",
      "sian to English, English to Hindi, and Hindi to\n",
      "English.\n",
      "For general domain Chinese⇔English and\n",
      "English⇔Russian, we sample source sentences\n",
      "from test sets of WMT2023 and WMT2022, re-\n",
      "spectively. For Chinese⇔Hindi, we extract source\n",
      "news text from public websites. For multi-domain\n",
      "evaluation data, we evaluate two domains, i.e.,\n",
      "biomedical and technology and we evaluate Chi-\n",
      "nese to English. The source sentences are extracted\n",
      "news texts from public websites. We ensure that\n",
      "all sources are source language origin to avoid the\n",
      "effect of translationese. We manually evaluate all\n",
      "source sentences for these tasks and ensure the\n",
      "source sentences are not too easy or too short. Fi-\n",
      "nally, each task contains 200 sentences, making our\n",
      "evaluation a total of 1600 sentences.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "|Annotators|A B C D E F|\n",
      "|---|---|\n",
      "|A B C D E F|100.0 57.5 65.0 65.0 62.5 67.5 &amp;#45; 100.0 52.5 52.5 50.0 50.0 &amp;#45; &amp;#45; 100.0 65.0 82.5 67.5 &amp;#45; &amp;#45; &amp;#45; 100.0 57.5 62.5 &amp;#45; &amp;#45; &amp;#45; &amp;#45; 100.0 70.0 &amp;#45; &amp;#45; &amp;#45; &amp;#45; &amp;#45; 100.0|\n",
      "|p&amp;#45;value|1.000 0.038 0.268 0.081 0.154 0.875|\n",
      "\fType\n",
      "Error Name\n",
      "Explanations\n",
      "Accuracy\n",
      "Mistranslation\n",
      "Translation does not accurately represent the source.\n",
      "Addition\n",
      "Information not present in the source.\n",
      "MT Hallucination\n",
      "Information that has nothing related to source; or gibber-\n",
      "ish; or repeats\n",
      "Omission\n",
      "Missing content from the source.\n",
      "Untranslated\n",
      "Not translated.\n",
      "Wrong Name Entity and Term\n",
      "Wrong usage of NE and Terminology.\n",
      "Fluency\n",
      "Grammar\n",
      "Problems with grammar of target language.\n",
      "Punctuation\n",
      "Incorrect punctuation (for locale or style)\n",
      "Spelling\n",
      "Incorrect spelling or capitalization.\n",
      "Register\n",
      "Wrong grammatical register (e.g., inappropriately infor-\n",
      "mal pronouns).\n",
      "Inconsistent Style\n",
      "Internal inconsistency ( not related to terminology )\n",
      "Unnatural Flow\n",
      "Translations that are too literal or sound unnatural.\n",
      "Other\n",
      "Non-translation\n",
      "-\n",
      "Table 2: Error category and explanations. We mainly follow the guidelines from Unbabel, and merge some\n",
      "errors to reduce the efforts for annotators to understand the annotation system. Concrete examples for\n",
      "each error category can be found in the Appendix.\n",
      "4.2\n",
      "Human Translators and Machine\n",
      "Translators\n",
      "We ask different human translators to translate our\n",
      "source sentences into the target language. Transla-\n",
      "tors are of three different levels of expertise, cate-\n",
      "gorized into junior-level, medium-level, and senior-\n",
      "level translators. The level of expertise is ranked\n",
      "by in-house criteria covering the translators’ edu-\n",
      "cational background, translation experience, and\n",
      "practical proficiency. See Appendix A for more de-\n",
      "tails. For a fair comparison, we request the experts\n",
      "not use machine translation or GPTs as assistance.\n",
      "For all directions except Zh-Hi and Hi-Zh, we col-\n",
      "lect three human translation results from each level\n",
      "of expertise. For Zh-Hi and Hi-Zh, we only have\n",
      "medium-level and senior-level translators due to\n",
      "the scarcity of translators.\n",
      "Except\n",
      "for\n",
      "human\n",
      "translators,\n",
      "we\n",
      "use\n",
      "gpt-4-1106-preview,\n",
      "the\n",
      "current\n",
      "state-\n",
      "of-the-art large language model released by\n",
      "OpenAI and Seamless M4T (Communication\n",
      "et al., 2023) as the representative of traditional ma-\n",
      "chine translations to complement our experiments.\n",
      "We directly prompt GPT-4 to obtain the translation,\n",
      "as it is the most common practice for normal users,\n",
      "the easiest to reproduce, and to avoid confusion by\n",
      "various techniques.\n",
      "4.3\n",
      "Prompt Search\n",
      "Previous study (Zhao et al., 2021; Liu et al., 2023a)\n",
      "shows that different prompts with LLMs can result\n",
      "in distinctive performance. Thus, we collect three\n",
      "candidate prompts used in previous research (Xu\n",
      "et al., 2023; Jiao et al., 2023a) and use COMET-\n",
      "QE (Rei et al., 2020b) to select the best prompt\n",
      "to make the best use of GPT-4, as shown in Table\n",
      "3. In particular, we use these three prompts to\n",
      "prompt GPT-4 to translate 100 source sentences in\n",
      "our Chinese-to-English test set and adopt COMET-\n",
      "QE to evaluate the quality of translations. We find\n",
      "that the third prompt yields the best performance,\n",
      "and hence we adopt this prompt for all following\n",
      "experiments.\n",
      "4.4\n",
      "Annotation Protocol\n",
      "To evaluate the results of candidates’ systems,\n",
      "we hire experts to annotate the errors of trans-\n",
      "lations blindly. The annotation platform is Doc-\n",
      "cano (Nakayama et al., 2018), and the error tags\n",
      "are made according to MQM standards. MQM\n",
      "requires the annotators to annotate the span of er-\n",
      "rors in each hypothesis. All hypotheses of the same\n",
      "source sentence are shown to the annotator together\n",
      "to help decide which is better. We have 13 error\n",
      "categories and two severities, as shown in Table\n",
      "2. Our categorization for errors mostly follows\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "|Type|Error Name|Explanations|\n",
      "|---|---|---|\n",
      "|Accuracy|Mistranslation|Translation does not accurately represent the source.|\n",
      "||Addition|Information not present in the source.|\n",
      "||MT Hallucination|Information that has nothing related to source; or gibber&amp;#45; ish; or repeats|\n",
      "||Omission|Missing content from the source.|\n",
      "||Untranslated|Not translated.|\n",
      "||Wrong Name Entity and Term|Wrong usage of NE and Terminology.|\n",
      "|Fluency|Grammar|Problems with grammar of target language.|\n",
      "||Punctuation|Incorrect punctuation (for locale or style)|\n",
      "||Spelling|Incorrect spelling or capitalization.|\n",
      "||Register|Wrong grammatical register (e.g., inappropriately infor&amp;#45; mal pronouns).|\n",
      "||Inconsistent Style|Internal inconsistency ( not related to terminology )|\n",
      "||Unnatural Flow|Translations that are too literal or sound unnatural.|\n",
      "|Other|Non&amp;#45;translation|&amp;#45;|\n",
      "\fPrompt\n",
      "COMET\n",
      "Please translate the following sen-\n",
      "tence from Chinese into English.\n",
      "Your language and style should align\n",
      "with the language conventions of a\n",
      "native speaker. \\n{SOURCE}\\n\n",
      "0.775\n",
      "You are an expert translator for trans-\n",
      "lating Chinese to English.\n",
      "Your\n",
      "language and style should align\n",
      "with the language conventions of\n",
      "a native speaker.\n",
      "\\n[Chinese]:\n",
      "{SOURCE}\\n[English]:\n",
      "0.755\n",
      "Please provide the English transla-\n",
      "tion for these sentences. Your lan-\n",
      "guage and style should align with\n",
      "the language conventions of a native\n",
      "speaker. \\n{SOURCE}\\n\n",
      "0.780\n",
      "Table 3: Taking Chinese to English as an example,\n",
      "our three prompts and corresponding scores with\n",
      "COMET-QE. {SOURCE} represents the source sen-\n",
      "tence to be translated.\n",
      "Unbabel’s practice 2 and we focus on most com-\n",
      "mon error types. Each tag has subtags with two\n",
      "severities, i.e., Minor or Major. A screenshot of the\n",
      "annotation system is given in Figure 5.\n",
      "For each task, we first ask the two expert anno-\n",
      "tators to carefully read our manual and conduct\n",
      "a training round on the first 10 groups of transla-\n",
      "tions. Then, we manually check these annotations\n",
      "to provide feedback and ask the two annotators to\n",
      "check their disagreements and revise their results.\n",
      "After two rounds of such training processes, we\n",
      "ask the annotators to finish the remaining sentences\n",
      "without knowing each other’s results.\n",
      "After the first round of annotation, we conduct a\n",
      "second round to further refine the evaluation results.\n",
      "In particular, we hire another two experts for each\n",
      "task and show them the previous annotation results.\n",
      "They are asked to approve and make necessary\n",
      "modifications to previous round annotations.\n",
      "4.5\n",
      "Inter-Annotator Agreement\n",
      "Error annotation with MQM is challenging, and\n",
      "previous work demonstrates that the agreement\n",
      "scores between MQM annotations are relatively\n",
      "low (Lommel et al., 2014). Reasons for this could\n",
      "be disagreement on precise spans and ambiguous\n",
      "2https://help.unbabel.\n",
      "com/hc/en-us/articles/\n",
      "6444304419479-Annotation-Guidelines-Typology-3-0\n",
      "Task\n",
      "Cohen Kappa(Segment)\n",
      "Krippendorffs(Span)\n",
      "Reference, Re-Annotated by (Freitag et al., 2021)\n",
      "WMT 2020 En-De\n",
      "0.208\n",
      "0.456\n",
      "WMT 2021 En-De\n",
      "0.230\n",
      "0.501\n",
      "Ours\n",
      "General Zh-En\n",
      "0.257\n",
      "0.436\n",
      "General En-Zh\n",
      "0.544\n",
      "0.579\n",
      "General En-Ru\n",
      "0.461\n",
      "0.566\n",
      "General Ru-En\n",
      "0.341\n",
      "0.875\n",
      "General Zh-Hi\n",
      "0.256\n",
      "0.443\n",
      "General Hi-Zh\n",
      "0.234\n",
      "0.495\n",
      "Technology Zh-En\n",
      "0.306\n",
      "0.581\n",
      "Biomedical Zh-En\n",
      "0.373\n",
      "0.616\n",
      "Average\n",
      "0.321\n",
      "0.555\n",
      "Table 4: Cohen Kappa (segment-level) and Krip-\n",
      "pendorffs’ Alpha (span-level) agreement of our an-\n",
      "notations.\n",
      "error categorization (Lommel et al., 2014). Despite\n",
      "the low agreement scores, MQM is more reliable\n",
      "than other evaluation protocols like Direct Assess-\n",
      "ment (Freitag et al., 2021).\n",
      "To compute inter-annotator agreement for MQM,\n",
      "we employ segment-level Cohen’s Kappa (Cohen,\n",
      "1960) and span-level Krippendorff’s alpha (Krip-\n",
      "pendorff, 1980). For reference, we calculate the\n",
      "agreement on the annotated results of the 2020 and\n",
      "2021 WMT English-to-German tasks by (Freitag\n",
      "et al., 2021). Our IAA results are shown in Table 4.\n",
      "Thanks to our two-round annotation process, our\n",
      "IAA scores show a favorable agreement, indicating\n",
      "a good annotation quality.\n",
      "5\n",
      "Main Results\n",
      "5.1\n",
      "Overall Results\n",
      "Analysis of Error Severity\n",
      "The upper part of\n",
      "Figure 1 plots the averaged number of errors of\n",
      "different systems and translators. Compared to our\n",
      "MT baseline (seamless), GPT-4 has much fewer er-\n",
      "rors. It performs almost as well as the junior-level\n",
      "translator at the level of total errors, as GPT-4 is\n",
      "annotated with only slightly more minor and major\n",
      "errors than junior translators. However, GPT-4 still\n",
      "has clear performance gaps between medium or\n",
      "senior human translators, as it makes considerably\n",
      "more mistakes than experienced translators. To our\n",
      "knowledge, we are the first to report how GPT-4 is\n",
      "on translation against human translators.\n",
      "Analysis of Error Categories\n",
      "Furthermore, we\n",
      "plot the categories of errors in the bottom part of\n",
      "Figure 1. Compared with junior human translators,\n",
      "GPT-4 makes more errors in the accuracy of trans-\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "|Prompt|COMET|\n",
      "|---|---|\n",
      "|Please translate the following sen&amp;#45; tence from Chinese into English. Your language and style should align with the language conventions of a native speaker. \\n{SOURCE}\\n|0.775|\n",
      "|You are an expert translator for trans&amp;#45; lating Chinese to English. Your language and style should align with the language conventions of a native speaker. \\n[Chinese]: {SOURCE}\\n[English]:|0.755|\n",
      "|Please provide the English transla&amp;#45; tion for these sentences. Your lan&amp;#45; guage and style should align with the language conventions of a native speaker. \\n{SOURCE}\\n|0.780|\n",
      "\n",
      "\n",
      "|Task|Cohen Kappa(Segment)|Krippendorffs(Span)|\n",
      "|---|---|---|\n",
      "|Reference, Re&amp;#45;Annotated by (Freitag et al., 2021)|||\n",
      "|WMT 2020 En&amp;#45;De|0.208|0.456|\n",
      "|WMT 2021 En&amp;#45;De|0.230|0.501|\n",
      "|Ours|||\n",
      "|General Zh&amp;#45;En|0.257|0.436|\n",
      "|General En&amp;#45;Zh|0.544|0.579|\n",
      "|General En&amp;#45;Ru|0.461|0.566|\n",
      "|General Ru&amp;#45;En|0.341|0.875|\n",
      "|General Zh&amp;#45;Hi|0.256|0.443|\n",
      "|General Hi&amp;#45;Zh|0.234|0.495|\n",
      "|Technology Zh&amp;#45;En|0.306|0.581|\n",
      "|Biomedical Zh&amp;#45;En|0.373|0.616|\n",
      "|Average|0.321|0.555|\n",
      "\fseamless\n",
      "gpt4\n",
      "junior\n",
      "medium\n",
      "senior\n",
      "Systems\n",
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "Number of Errors\n",
      "Average Severity for Each System\n",
      "Minor\n",
      "Major\n",
      "seamless\n",
      "gpt4\n",
      "junior\n",
      "medium\n",
      "senior\n",
      "Systems\n",
      "0\n",
      "25\n",
      "50\n",
      "75\n",
      "100\n",
      "125\n",
      "150\n",
      "175\n",
      "200\n",
      "Number of Errors\n",
      "Error Category for Each System\n",
      "Accuracy\n",
      "Fluency\n",
      "Figure 1: Upper: Error severity for each system.\n",
      "The gray line represents the standard deviation for\n",
      "each system across tasks. Bottom: Error category\n",
      "analysis for each system.\n",
      "lations, which accounts for most of the disparity.\n",
      "Interestingly, GPT-4 surpasses junior translators\n",
      "in fluency issues, denoting a better capability of\n",
      "language usage.\n",
      "In addition, Figure 2 shows the top 5 categories\n",
      "of errors made by different systems. ‘Mistransla-\n",
      "tion’ is the most frequent error made by all systems.\n",
      "Improving much over the seamless baseline, GPT-\n",
      "4 makes comparable numbers of ‘Mistranslation’\n",
      "with junior and medium human translators.\n",
      "For all translators, ‘Unnatural Flow’ is among\n",
      "the most frequent errors. Seamless, GPT-4, and\n",
      "junior translators have similar levels of ‘Unnatural\n",
      "Flow’, indicating possible issues of literal transla-\n",
      "tion and not following language conventions. In\n",
      "contrast, medium and senior translators are anno-\n",
      "tated with significantly fewer errors of ‘Unnatural\n",
      "Flow’.\n",
      "In addition, we notice even though GPT-4 makes\n",
      "Mistranslation\n",
      "Punctuation\n",
      "Wrong NE\n",
      "Unnatural Flow\n",
      "Omission\n",
      "Mistranslation\n",
      "Unnatural Flow\n",
      "Wrong NE\n",
      "Grammar\n",
      "Punctuation\n",
      "Mistranslation\n",
      "Unnatural Flow\n",
      "Grammar\n",
      "Wrong NE\n",
      "Punctuation\n",
      "Mistranslation\n",
      "Unnatural Flow\n",
      "Wrong NE\n",
      "Omission\n",
      "Grammar\n",
      "Mistranslation\n",
      "Unnatural Flow\n",
      "Addition\n",
      "Punctuation\n",
      "Grammar\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "Number of Errors\n",
      "Top5 Error Categories\n",
      "seamless\n",
      "gpt4\n",
      "junior\n",
      "medium\n",
      "senior\n",
      "Figure 2: Top 5 categories of errors made by each\n",
      "system.\n",
      "much fewer ‘Wrong Name Entity(NE)’ errors com-\n",
      "pared to Seamless, which could be beneficial be-\n",
      "cause of its huge knowledge acquired in the pre-\n",
      "training stage, it still has a gap compared to human\n",
      "translators.\n",
      "Finally, we notice that GPT-4 does not have\n",
      "Omission or Addition problems in its top-5 errors,\n",
      "whereas even senior translators have Addition er-\n",
      "rors.\n",
      "5.2\n",
      "Detailed Results for Each Language\n",
      "In Figure 3, we present detailed results for each\n",
      "language pair, averaged over two directions.\n",
      "English-Chinese\n",
      "From Figure 3(a),\n",
      "GPT-4\n",
      "shows the great capability of translating English\n",
      "to Chinese and vice versa. From the radar chart,\n",
      "we can see that GPT-4 makes almost the same or\n",
      "slightly fewer semantic errors (Omission, Addition,\n",
      "and Mistranslation errors) than Junior and Senior\n",
      "translators. Especially mistranslation errors, which\n",
      "are generally considered most semantically detri-\n",
      "mental, are better than junior and senior translators.\n",
      "For omission and addition errors, GPT-4 reaches al-\n",
      "most the same level as senior translators. However,\n",
      "GPT-4 made significantly more lexical, stylistic,\n",
      "and grammatical errors than human translators do.\n",
      "The error distribution of translation of GPT-4 meets\n",
      "our expectations, as in the absence of reference,\n",
      "GPT-4 will translate unfamiliar words directly and\n",
      "literally instead of seeking online materials or other\n",
      "forms of help like human translators. Furthermore,\n",
      "due to the complexity and variability of Chinese,\n",
      "the translation of entity names or proper nouns is\n",
      "usually not one-to-one, two above reasons together\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "|Average Severity for Each System Minor|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|Col10|Col11|Col12|Col13|Minor|Col15|\n",
      "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
      "|Minor Major|||||||||||||Minor Major||\n",
      "||||||||||||||||\n",
      "||||||||||||||||\n",
      "||||||||||||||||\n",
      "||||||||||||||||\n",
      "||||||||||||||||\n",
      "||||||||||||||||\n",
      "||||||||||||||||\n",
      "||||||||||||||||\n",
      "\n",
      "\n",
      "|Top5 Error Categories|Col2|Col3|Col4|Col5|seamless|\n",
      "|---|---|---|---|---|---|\n",
      "||||||seamless|\n",
      "||||||gpt4 junior medium|\n",
      "||senior||||senior|\n",
      "|||||||\n",
      "|||||||\n",
      "|||||||\n",
      "|||||||\n",
      "|||||||\n",
      "|||||||\n",
      "\n",
      "\n",
      "|Error Category for Each System|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|Col10|Col11|Col12|Col13|Col14|Col15|Col16|Col17|\n",
      "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
      "||||||||||||||Accuracy Fluency||||\n",
      "||||||||||||||||||\n",
      "||||||||||||||||||\n",
      "||||||||||||||||||\n",
      "||||||||||||||||||\n",
      "||||||||||||||||||\n",
      "||||||||||||||||||\n",
      "||||||||||||||||||\n",
      "||||||||||||||||||\n",
      "||||||||||||||||||\n",
      "||||||||||||||||||\n",
      "||||||||||||||||||\n",
      "||||||||||||||||||\n",
      "||||||||||||||||||\n",
      "\fMistranslation(130)\n",
      "Addition(4)\n",
      "MT Hallucination(14)\n",
      "Omission(29)\n",
      "Untranslated(0)\n",
      "Wrong Name Entity & Term(78)\n",
      "Grammar(9)\n",
      "Punctuation(11)\n",
      "Spelling(4)\n",
      "Register(8)\n",
      "Inconsistent Style(0)\n",
      "Non-translation(0)\n",
      "Unnatural Flow(0)\n",
      "0.0 0.2 0.4 0.6 0.8 1.0\n",
      "seamless\n",
      "gpt4\n",
      "junior\n",
      "medium\n",
      "senior\n",
      "(a) Chinese↔English\n",
      "Mistranslation(20)\n",
      "Addition(8)\n",
      "MT Hallucination(0)\n",
      "Omission(17)\n",
      "Untranslated(2)\n",
      "Wrong Name Entity & Term(1)\n",
      "Grammar(5)\n",
      "Punctuation(3)\n",
      "Spelling(3)\n",
      "Register(0)\n",
      "Inconsistent Style(3)\n",
      "Non-translation(0)\n",
      "Unnatural Flow(0)\n",
      "0.0\n",
      "0.2\n",
      "0.4\n",
      "0.6\n",
      "0.8\n",
      "1.0\n",
      "seamless\n",
      "gpt4\n",
      "junior\n",
      "medium\n",
      "senior\n",
      "(b) English↔Russian\n",
      "Mistranslation(52)\n",
      "Addition(6)\n",
      "MT Hallucination(5)\n",
      "Omission(9)\n",
      "Untranslated(6)\n",
      "Wrong Name Entity & Term(7)\n",
      "Grammar(6)\n",
      "Punctuation(10)\n",
      "Spelling(3)\n",
      "Register(1)\n",
      "Inconsistent Style(1)\n",
      "Non-translation(0)\n",
      "Unnatural Flow(0)\n",
      "0.0\n",
      "0.2\n",
      "0.4\n",
      "0.6\n",
      "0.8\n",
      "1.0\n",
      "seamless\n",
      "gpt4\n",
      "medium\n",
      "senior\n",
      "(c) Chinese↔Hindi\n",
      "Figure 3: Error category results for each language. Each sub-figure is the average over two directions.\n",
      "We only include ‘Major’ errors here to highlight the most severe problems. Higher values indicate more\n",
      "errors and the number after each error type is the maximum number of that error.\n",
      "cause the inferiority of the performance of GPT-4\n",
      "in these aspects.\n",
      "English-Russian\n",
      "For the English-Russian trans-\n",
      "lation tasks, GPT-4 made slightly more semantic\n",
      "errors but the number of mistranslation errors made\n",
      "by GPT-4 is almost at the same level as medium\n",
      "and senior translators. However, GPT-4 generally\n",
      "made less stylistic, grammatical, and wrong name\n",
      "entity & term than junior translators. The English-\n",
      "Russian translation tasks are quite challenging and\n",
      "the performance of translators varies significantly,\n",
      "but GPT-4 still maintains the average level overall.\n",
      "Hindi-Chinese\n",
      "As the low-resource language\n",
      "pair we evaluate, GPT-4 demonstrates the worst\n",
      "performance across evaluated translators. We ob-\n",
      "serve that GPT4 is inferior to our MT baseline. This\n",
      "may be due to the small portion of Hindi and Chi-\n",
      "nese corpora in its pre-training dataset. Specifically,\n",
      "making the most ‘Mistranslation’ errors of GPT-4\n",
      "indicates a distance away from the language under-\n",
      "standing of human translators. As a comparison,\n",
      "SeamlessM4T performs better in both semantic and\n",
      "lexical errors.\n",
      "Discussion\n",
      "Our results here manifest an imbal-\n",
      "ance of multilinguality for LLMs (Wang et al.,\n",
      "2023b). Our results imply that GPT-4 can serve\n",
      "as a reliable translator for resource-high such as\n",
      "Chinese to English but is doubtful for low-resource\n",
      "directions like Chinese-Hindi. In the low-resource\n",
      "scenario, machine translator is more reliable.\n",
      "5.3\n",
      "Detailed Results for Different Domains\n",
      "Figure 4 presents our results for different domains\n",
      "in Chinese-to-English translation. We compare\n",
      "three different domains, including news, technol-\n",
      "ogy, and biomedical.\n",
      "General News Domain\n",
      "GPT-4 performs worse\n",
      "in the news domain than human translators of three\n",
      "levels. The number of semantic errors made by\n",
      "GPT-4 is quite close to junior and medium transla-\n",
      "tors. Nonetheless, GPT-4 made more lexical and\n",
      "grammatical errors compared to human translators.\n",
      "We hypothesize the reasons for the situation de-\n",
      "scribed above to happen are mainly because of the\n",
      "literariness and timeliness. Because GPT-4 is not\n",
      "able to access the online materials to confirm the\n",
      "name of a specific entity or event.\n",
      "Technology Domain\n",
      "The performance of GPT-4\n",
      "is relatively close to medium-level translators. Ex-\n",
      "cept for the Wrong Name Entity & Terms, GPT-4\n",
      "makes almost the same or even fewer errors than\n",
      "medium-level translators across all aspects. Specif-\n",
      "ically, the number of semantic errors made by GPT-\n",
      "4 is almost the same to medium-level translators\n",
      "and it makes much fewer structural and grammati-\n",
      "cal errors. It means that in this field, GPT-4 might\n",
      "understand the original text better than junior or\n",
      "medium-level translators and be able to conduct\n",
      "a translation that is more in line with the original\n",
      "meaning.\n",
      "Biomedical Domain\n",
      "Similar to the technology\n",
      "domain, the qualities of the translations made by\n",
      "GPT-4 and medium-level translators stand at the\n",
      "\fMistranslation(105)\n",
      "Addition(4)\n",
      "MT Hallucination(2)\n",
      "Omission(27)\n",
      "Untranslated(0)\n",
      "Wrong Name Entity & Term(75)\n",
      "Grammar(9)\n",
      "Punctuation(7)\n",
      "Spelling(2)\n",
      "Register(6)\n",
      "Inconsistent Style(0)\n",
      "Non-translation(0)\n",
      "Unnatural Flow(0)\n",
      "0.0 0.2 0.4 0.6 0.8 1.0\n",
      "seamless\n",
      "gpt4\n",
      "junior\n",
      "medium\n",
      "senior\n",
      "(a) General news domain.\n",
      "Mistranslation(114)\n",
      "Addition(3)\n",
      "MT Hallucination(2)\n",
      "Omission(57)\n",
      "Untranslated(0)\n",
      "Wrong Name Entity & Term(157)\n",
      "Grammar(30)\n",
      "Punctuation(9)\n",
      "Spelling(3)\n",
      "Register(8)\n",
      "Inconsistent Style(5)\n",
      "Non-translation(0)\n",
      "Unnatural Flow(0)\n",
      "0.0 0.2 0.4 0.6 0.8 1.0\n",
      "seamless\n",
      "gpt4\n",
      "junior\n",
      "medium\n",
      "senior\n",
      "(b) Technology domain.\n",
      "Mistranslation(21)\n",
      "Addition(0)\n",
      "MT Hallucination(3)\n",
      "Omission(9)\n",
      "Untranslated(0)\n",
      "Wrong Name Entity & Term(49)\n",
      "Grammar(0)\n",
      "Punctuation(2)\n",
      "Spelling(1)\n",
      "Register(0)\n",
      "Inconsistent Style(0)\n",
      "Non-translation(0)\n",
      "Unnatural Flow(0)\n",
      "0.0\n",
      "0.2\n",
      "0.4\n",
      "0.6\n",
      "0.8\n",
      "1.0\n",
      "seamless\n",
      "gpt4\n",
      "junior\n",
      "medium\n",
      "senior\n",
      "(c) Biomedical domain.\n",
      "Figure 4: Error category results for different domains in Chinese-to-English. We only include ‘Major’\n",
      "errors here to highlight the most severe problems. Higher values indicate more errors and the number in\n",
      "the bracket is the maximum number of that error.\n",
      "Source\n",
      "巨人网络有限公司\n",
      "GPT-4\n",
      "Giant Network Group Inc.\n",
      "Human\n",
      "Giant Interactive Group Inc.\n",
      "Table 5: Named Entity cases.\n",
      "same level. Despite slightly more Wrong Name\n",
      "Entity & Terms errors made, GPT-4 performs better\n",
      "than junior and medium-level translators in other\n",
      "aspects.\n",
      "Discussion\n",
      "For specific domains like technol-\n",
      "ogy, we show that GPT-4 is comparable with ju-\n",
      "nior/medium translators. We still notice a similar\n",
      "imbalance issue as in the multilingual setting, but\n",
      "GPT-4’s performance is not as sensitive as in the\n",
      "change of language.\n",
      "5.4\n",
      "Case Study\n",
      "We also qualitatively understand the difference be-\n",
      "tween the translations given by GPT-4 and human\n",
      "translators.\n",
      "Literal Translations\n",
      "Among the error cases, the\n",
      "typical one is literal translations. Specifically, we\n",
      "find that GPT-4 sometimes translates with semanti-\n",
      "cally correct, but in-native and literal translations.\n",
      "This is problematic with named entities, especially\n",
      "those occurring less frequently. As shown in Table\n",
      "5, when not knowing the correct translation of ‘巨\n",
      "人网络有限公司’, GPT-4 translates the term word\n",
      "by word. However, the issue of name entities oc-\n",
      "curs less for human translators, partially because\n",
      "they would google it to find the correct translation.\n",
      "Source\n",
      "It’s just a white screen or it times out load-\n",
      "ing it, or the page becomes unresponsive!\n",
      "GPT-4\n",
      "它只是一个白屏，要么是加载时超时，\n",
      "要么页面变得无响应了！\n",
      "Human\n",
      "页面要么显示空白，要么加载超时或是\n",
      "无响应。\n",
      "Table 6: Unnatural-Flow cases. Red represents the\n",
      "literal translation and green is more natural and\n",
      "native in Chinese.\n",
      "Thus, this issue might be resolved by incorporating\n",
      "web-search into agent-like translation (Feng et al.,\n",
      "2024; Wu et al., 2024c).\n",
      "Except for named entities, we notice that the\n",
      "literal translation causes Unnatural Flows.\n",
      "As\n",
      "shown in Table 6, when translating ‘It’s just a white\n",
      "screen’, GPT-4 translates the phrase to ‘它(it)只\n",
      "是(is just)一个(a)白屏(white screen)’, but human\n",
      "translator translates this phrase to ‘‘页面显示空\n",
      "白(The page display is white)’’, which represents\n",
      "a preciser meaning and follows local conventions.\n",
      "Human Imagination\n",
      "We find human translators\n",
      "also have drawbacks compared to the GPT-4 trans-\n",
      "lator. When the source sentence contains insuffi-\n",
      "cient information to translate, human translators\n",
      "tend to fill the gap by imagination or overthinking.\n",
      "An example is given in Table 7. The translator\n",
      "wrongly understands the phrase ‘entering his 2nd\n",
      "year’ as Daley is a two-year-old baby, but the sen-\n",
      "tence describes a 2nd-year player for sports. This\n",
      "may be due to daily language habits, misunder-\n",
      "\fSource\n",
      "He\n",
      "has\n",
      "health\n",
      "concerns\n",
      "atm\n",
      "but\n",
      "we also have Daley entering his 2nd year\n",
      "and is a decent safety net.\n",
      "GPT-4\n",
      "他目前有健康问题，但我们还有戴利进\n",
      "入他的第二年，他是一个不错的安全保\n",
      "障。\n",
      "Human\n",
      "他目前有健康问题。不过，戴利两岁\n",
      "了，是个不错的备选人。\n",
      "Table 7: Human imagination cases. Red denotes the\n",
      "imagined part.\n",
      "standing, or not paying attention, and could be\n",
      "related to the hallucination (Zhang et al., 2023) of\n",
      "LLMs. GPT-4’s literal translation helps in this, as\n",
      "it keeps faithful to the source sentence. This also\n",
      "aligns with our findings in Section 5.1 that GPT-4\n",
      "has fewer Additions or Omissions.\n",
      "6\n",
      "Conclusion\n",
      "In this study, we comprehensively evaluated the\n",
      "translation quality of GPT-4 against human trans-\n",
      "lators of varying expertise levels across multiple\n",
      "language pairs and domains. Our findings showed\n",
      "that GPT-4 performs comparably to junior transla-\n",
      "tors in terms of total errors made but lags behind\n",
      "medium and senior translators. We also notice that\n",
      "GPT-4’s translation capability gradually weakens\n",
      "from resource-rich to resource-poor language pairs.\n",
      "Qualitative analysis revealed that GPT-4 tends to\n",
      "produce more literal translations compared to hu-\n",
      "man translators but suffers less from imagined in-\n",
      "formation.\n",
      "The results of this study demonstrate that GPT-4\n",
      "has made significant strides in approaching human-\n",
      "level translation quality, as well as highlighting the\n",
      "nuanced difference between them. This suggests\n",
      "promising opportunities for collaboration and en-\n",
      "hancement of translation workflows. As research\n",
      "continues to advance, we anticipate that LLMs will\n",
      "become increasingly valuable tools in the trans-\n",
      "lation industry, working alongside human transla-\n",
      "tors to improve productivity, efficiency, and overall\n",
      "translation quality.\n",
      "7\n",
      "Limitations\n",
      "Our work is limited in the following aspects: (1)\n",
      "We benchmark GPT-4 for translation tasks, as it is\n",
      "a representative large language model and shows\n",
      "state-of-the-art performance for many text-based\n",
      "tasks. However, our evaluations can be extended\n",
      "to other LLMs such as Claude-3. (2) Our eval-\n",
      "uation covers three languages and six directions\n",
      "from resource-rich to resource-poor. However, for\n",
      "other languages, there might be linguistic-specific\n",
      "phenomena that are not covered in this paper.\n",
      "References\n",
      "Guangsheng Bao, Yanbin Zhao, Zhiyang Teng,\n",
      "Linyi Yang, and Yue Zhang. 2023.\n",
      "Fast-\n",
      "detectgpt:\n",
      "Efficient zero-shot detection of\n",
      "machine-generated text via conditional probabil-\n",
      "ity curvature. arXiv preprint arXiv:2310.05130.\n",
      "Ljubisa Bojic, Predrag Kovacevic, and Milan\n",
      "Cabarkapa. 2023.\n",
      "Gpt-4 surpassing human\n",
      "performance in linguistic pragmatics.\n",
      "arXiv\n",
      "preprint arXiv:2312.09545.\n",
      "Jacob Cohen. 1960. A coefficient of agreement for\n",
      "nominal scales. Educational and psychological\n",
      "measurement, 20(1):37–46.\n",
      "Seamless Communication, Loïc Barrault, Yu-An\n",
      "Chung, Mariano Cora Meglioli, David Dale,\n",
      "Ning Dong, Paul-Ambroise Duquenne, Hady\n",
      "Elsahar, Hongyu Gong, Kevin Heffernan, John\n",
      "Hoffman, Christopher Klaiber, Pengwei Li,\n",
      "Daniel Licht, Jean Maillard, Alice Rakotoari-\n",
      "son, Kaushik Ram Sadagopan, Guillaume Wen-\n",
      "zek, Ethan Ye, Bapi Akula, Peng-Jen Chen,\n",
      "Naji El Hachem, Brian Ellis, Gabriel Mejia\n",
      "Gonzalez, Justin Haaheim, Prangthip Hansanti,\n",
      "Russ Howes, Bernie Huang, Min-Jae Hwang,\n",
      "Hirofumi Inaguma, Somya Jain, Elahe Kalbassi,\n",
      "Amanda Kallet, Ilia Kulikov, Janice Lam, Daniel\n",
      "Li, Xutai Ma, Ruslan Mavlyutov, Benjamin Pelo-\n",
      "quin, Mohamed Ramadan, Abinesh Ramakrish-\n",
      "nan, Anna Sun, Kevin Tran, Tuan Tran, Igor\n",
      "Tufanov, Vish Vogeti, Carleigh Wood, Yilin\n",
      "Yang, Bokai Yu, Pierre Andrews, Can Balioglu,\n",
      "Marta R. Costa-jussà, Onur Celebi, Maha El-\n",
      "bayad, Cynthia Gao, Francisco Guzmán, Justine\n",
      "Kao, Ann Lee, Alexandre Mourachko, Juan Pino,\n",
      "Sravya Popuri, Christophe Ropers, Safiyyah\n",
      "Saleem, Holger Schwenk, Paden Tomasello,\n",
      "Changhan Wang, Jeff Wang, and Skyler Wang.\n",
      "2023. Seamlessm4t: Massively multilingual &\n",
      "multimodal machine translation.\n",
      "Maxim Enis and Mark Hopkins. 2024.\n",
      "From\n",
      "llm to nmt:\n",
      "Advancing low-resource ma-\n",
      "\fchine translation with claude. arXiv preprint\n",
      "arXiv:2404.13813.\n",
      "Akhbardeh Farhad,\n",
      "Arkhangorodsky Arkady,\n",
      "Biesialska Magdalena, Bojar Ondˇrej, Chatterjee\n",
      "Rajen, Chaudhary Vishrav, Marta R Costa-jussa,\n",
      "España-Bonet Cristina, Fan Angela, Federmann\n",
      "Christian, et al. 2021. Findings of the 2021 con-\n",
      "ference on machine translation (wmt21). In Pro-\n",
      "ceedings of the Sixth Conference on Machine\n",
      "Translation, pages 1–88. Association for Com-\n",
      "putational Linguistics.\n",
      "Zhaopeng Feng, Yan Zhang, Hao Li, Bei Wu, Jiayu\n",
      "Liao, Wenqiang Liu, Jun Lang, Yang Feng, Jian\n",
      "Wu, and Zuozhu Liu. 2024. Tear: Improving\n",
      "llm-based machine translation with systematic\n",
      "self-refinement.\n",
      "Lukas Fischer and Samuel L¨\"aubli. 2020. What’s\n",
      "the difference between professional human and\n",
      "machine translation?\n",
      "a blind multi-language\n",
      "study on domain-specific MT. In Proceedings\n",
      "of the 22nd Annual Conference of the European\n",
      "Association for Machine Translation, pages 215–\n",
      "224, Lisboa, Portugal. European Association for\n",
      "Machine Translation.\n",
      "Markus Freitag, George Foster, David Grang-\n",
      "ier, Viresh Ratnakar, Qijun Tan, and Wolfgang\n",
      "Macherey. 2021. Experts, errors, and context:\n",
      "A large-scale study of human evaluation for ma-\n",
      "chine translation. Transactions of the Associ-\n",
      "ation for Computational Linguistics, 9:1460–\n",
      "1474.\n",
      "Markus Freitag, Nitika Mathur, Chi-kiu Lo, Eleft-\n",
      "herios Avramidis, Ricardo Rei, Brian Thompson,\n",
      "Tom Kocmi, Frederic Blain, Daniel Deutsch,\n",
      "Craig Stewart, Chrysoula Zerva, Sheila Castilho,\n",
      "Alon Lavie, and George Foster. 2023. Results\n",
      "of WMT23 metrics shared task: Metrics might\n",
      "be guilty but references are not innocent. In Pro-\n",
      "ceedings of the Eighth Conference on Machine\n",
      "Translation, pages 578–628, Singapore. Associ-\n",
      "ation for Computational Linguistics.\n",
      "Markus Freitag, Ricardo Rei, Nitika Mathur, Chi-\n",
      "kiu Lo, Craig Stewart, Eleftherios Avramidis,\n",
      "Tom Kocmi, George Foster, Alon Lavie, and\n",
      "André F. T. Martins. 2022. Results of WMT22\n",
      "metrics shared task: Stop using BLEU – neu-\n",
      "ral metrics are better and more robust. In Pro-\n",
      "ceedings of the Seventh Conference on Machine\n",
      "Translation (WMT), pages 46–68, Abu Dhabi,\n",
      "United Arab Emirates (Hybrid). Association for\n",
      "Computational Linguistics.\n",
      "Tanya Goyal, Junyi Jessy Li, and Greg Durrett.\n",
      "2022. News summarization and evaluation in the\n",
      "era of gpt-3. arXiv preprint arXiv:2209.12356.\n",
      "Yvette Graham, Timothy Baldwin, Alistair Mof-\n",
      "fat, and Justin Zobel. 2013. Continuous mea-\n",
      "surement scales in human evaluation of machine\n",
      "translation. In Proceedings of the 7th Linguis-\n",
      "tic Annotation Workshop and Interoperability\n",
      "with Discourse, pages 33–41, Sofia, Bulgaria.\n",
      "Association for Computational Linguistics.\n",
      "Yvette Graham, Christian Federmann, Maria Es-\n",
      "kevich, and Barry Haddow. 2020. Assessing\n",
      "human-parity in machine translation on the seg-\n",
      "ment level. In Findings of the Association for\n",
      "Computational Linguistics: EMNLP 2020, pages\n",
      "4199–4207, Online. Association for Computa-\n",
      "tional Linguistics.\n",
      "Tianyu Han, Lisa C Adams, Keno Bressem, Fe-\n",
      "lix Busch, Luisa Huck, Sven Nebelung, and\n",
      "Daniel Truhn. 2023. Comparative analysis of\n",
      "gpt-4vision, gpt-4 and open source llms in clin-\n",
      "ical diagnostic accuracy: A benchmark against\n",
      "human expertise. medRxiv, pages 2023–11.\n",
      "Hany Hassan, Anthony Aue, Chang Chen, Vishal\n",
      "Chowdhary, Jonathan Clark, Christian Fed-\n",
      "ermann, Xuedong Huang, Marcin Junczys-\n",
      "Dowmunt, William Lewis, Mu Li, et al. 2018.\n",
      "Achieving human parity on automatic chinese\n",
      "to english news translation.\n",
      "arXiv preprint\n",
      "arXiv:1803.05567.\n",
      "Dan Hendrycks, Collin Burns, Steven Basart, Andy\n",
      "Zou, Mantas Mazeika, Dawn Song, and Jacob\n",
      "Steinhardt. 2021. Measuring massive multitask\n",
      "language understanding.\n",
      "Amr Hendy, Mohamed Abdelrehim, Amr Sharaf,\n",
      "Vikas Raunak, Mohamed Gabr, Hitokazu Mat-\n",
      "sushita, Young Jin Kim, Mohamed Afify, and\n",
      "Hany Hassan Awadalla. 2023. How good are gpt\n",
      "models at machine translation? a comprehensive\n",
      "evaluation. arXiv preprint arXiv:2302.09210.\n",
      "Hui Huang, Shuangzhi Wu, Xinnian Liang, Bing\n",
      "Wang, Yanrui Shi, Peihao Wu, Muyun Yang, and\n",
      "Tiejun Zhao. 2023. Towards making the most of\n",
      "\fllm for translation quality estimation. In CCF\n",
      "International Conference on Natural Language\n",
      "Processing and Chinese Computing, pages 375–\n",
      "386. Springer.\n",
      "Wenxiang Jiao, Wenxuan Wang, Jen tse Huang,\n",
      "Xing Wang, Shuming Shi, and Zhaopeng Tu.\n",
      "2023a. Is chatgpt a good translator? yes with\n",
      "gpt-4 as the engine.\n",
      "Wenxiang Jiao, Wenxuan Wang, Jen tse Huang,\n",
      "Xing Wang, Shuming Shi, and Zhaopeng Tu.\n",
      "2023b. Is chatgpt a good translator? yes with\n",
      "gpt-4 as the engine.\n",
      "Ahrii Kim, Yunju Bak, Jimin Sun, Sungwon Lyu,\n",
      "and Changmin Lee. 2023.\n",
      "The suboptimal\n",
      "wmt test sets and its impact on human parity.\n",
      "Preprints.\n",
      "Filip Klubiˇcka, Antonio Toral, and Víctor M\n",
      "Sánchez-Cartagena. 2018.\n",
      "Quantitative fine-\n",
      "grained human evaluation of machine transla-\n",
      "tion systems: a case study on english to croatian.\n",
      "Machine Translation, 32(3):195–215.\n",
      "Tom Kocmi, Eleftherios Avramidis, Rachel Baw-\n",
      "den, Ondˇrej Bojar, Anton Dvorkovich, Chris-\n",
      "tian Federmann, Mark Fishel, Markus Freitag,\n",
      "Thamme Gowda, Roman Grundkiewicz, et al.\n",
      "2023. Findings of the 2023 conference on ma-\n",
      "chine translation (wmt23): Llms are here but\n",
      "not quite there yet. In Proceedings of the Eighth\n",
      "Conference on Machine Translation, pages 1–42.\n",
      "Tom Kocmi, Rachel Bawden, Ondˇrej Bojar, Anton\n",
      "Dvorkovich, Christian Federmann, Mark Fishel,\n",
      "Thamme Gowda, Yvette Graham, Roman Grund-\n",
      "kiewicz, Barry Haddow, et al. 2022. Findings\n",
      "of the 2022 conference on machine translation\n",
      "(wmt22). In Proceedings of the Seventh Con-\n",
      "ference on Machine Translation (WMT), pages\n",
      "1–45.\n",
      "Klaus Krippendorff. 1980. Validity in content anal-\n",
      "ysis. Computerstrategien für die Kommunika-\n",
      "tionsanalyse, 69:45p.\n",
      "Yafu Li, Qintong Li, Leyang Cui, Wei Bi, Longyue\n",
      "Wang, Linyi Yang, Shuming Shi, and Yue Zhang.\n",
      "2023. Deepfake text detection in the wild. arXiv\n",
      "preprint arXiv:2305.13242.\n",
      "Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao\n",
      "Jiang, Hiroaki Hayashi, and Graham Neubig.\n",
      "2023a. Pre-train, prompt, and predict: A sys-\n",
      "tematic survey of prompting methods in natural\n",
      "language processing. ACM Computing Surveys,\n",
      "55(9):1–35.\n",
      "Zhengliang Liu, Tianyang Zhong, Yiwei Li, Yu-\n",
      "tong Zhang, Yi Pan, Zihao Zhao, Peixin Dong,\n",
      "Chao Cao, Yuxiao Liu, Peng Shu, et al. 2023b.\n",
      "Evaluating large language models for radiology\n",
      "natural language processing.\n",
      "arXiv preprint\n",
      "arXiv:2307.13693.\n",
      "Arle Lommel, Maja Popovic, and Aljoscha Bur-\n",
      "chardt. 2014. Assessing inter-annotator agree-\n",
      "ment for translation error annotation. In MTE:\n",
      "Workshop on Automatic and Manual Metrics for\n",
      "Operational Translation Evaluation, pages 31–\n",
      "37. Language Resources and Evaluation Confer-\n",
      "ence Reykjavik.\n",
      "Laurence T Maloney, Maria F Dal Martello, Vi-\n",
      "vian Fei, and Valerie Ma. 2024.\n",
      "A compar-\n",
      "ison of human and gpt-4 use of probabilistic\n",
      "phrases in a coordination game. Scientific re-\n",
      "ports, 14(1):6835.\n",
      "Hiroki Nakayama, Takahiro Kubo, Junya Ka-\n",
      "mura, Yasufumi Taniguchi, and Xu Liang.\n",
      "2018.\n",
      "doccano:\n",
      "Text\n",
      "annotation\n",
      "tool\n",
      "for\n",
      "human.\n",
      "Software\n",
      "available\n",
      "from\n",
      "https://github.com/doccano/doccano.\n",
      "Ha Nguyen and Vicki Allan. 2024. Using gpt-4\n",
      "to provide tiered, formative code feedback. In\n",
      "Proceedings of the 55th ACM Technical Sympo-\n",
      "sium on Computer Science Education V. 1, pages\n",
      "958–964.\n",
      "Keqin Peng, Liang Ding, Qihuang Zhong, Li Shen,\n",
      "Xuebo Liu, Min Zhang, Yuanxin Ouyang, and\n",
      "Dacheng Tao. 2023. Towards making the most\n",
      "of chatgpt for machine translation. In Findings\n",
      "of the Association for Computational Linguistics:\n",
      "EMNLP 2023, pages 5622–5633.\n",
      "Thierry Poibeau. 2022. On\" human parity\" and\" su-\n",
      "per human performance\" in machine translation\n",
      "evaluation. In Language Resource and Evalua-\n",
      "tion Conference.\n",
      "Ricardo Rei, Craig Stewart, Ana C Farinha, and\n",
      "Alon Lavie. 2020a. COMET: A neural frame-\n",
      "work for MT evaluation. In Proceedings of the\n",
      "\f2020 Conference on Empirical Methods in Natu-\n",
      "ral Language Processing (EMNLP), pages 2685–\n",
      "2702, Online. Association for Computational\n",
      "Linguistics.\n",
      "Ricardo Rei, Craig Stewart, Ana C Farinha, and\n",
      "Alon Lavie. 2020b. Comet: A neural frame-\n",
      "work for mt evaluation. In Proceedings of the\n",
      "2020 Conference on Empirical Methods in Natu-\n",
      "ral Language Processing (EMNLP), pages 2685–\n",
      "2702.\n",
      "Sai Cheong Siu. 2023. Chatgpt and gpt-4 for pro-\n",
      "fessional translators: Exploring the potential of\n",
      "large language models in translation. Available\n",
      "at SSRN 4448091.\n",
      "Antonio Toral, Sheila Castilho, Ke Hu, and Andy\n",
      "Way. 2018. Attaining the unattainable? reassess-\n",
      "ing claims of human parity in neural machine\n",
      "translation. In Proceedings of the Third Confer-\n",
      "ence on Machine Translation: Research Papers,\n",
      "pages 113–123, Brussels, Belgium. Association\n",
      "for Computational Linguistics.\n",
      "Longyue Wang, Chenyang Lyu, Tianbo Ji, Zhirui\n",
      "Zhang, Dian Yu, Shuming Shi, and Zhaopeng\n",
      "Tu. 2023a. Document-level machine translation\n",
      "with large language models.\n",
      "Wenxuan Wang, Wenxiang Jiao, Jingyuan Huang,\n",
      "Ruyi Dai, Jen-tse Huang, Zhaopeng Tu, and\n",
      "Michael R Lyu. 2023b. Not all countries cel-\n",
      "ebrate thanksgiving: On the cultural dominance\n",
      "in large language models. CoRR.\n",
      "Minghao Wu, Thuy-Trang Vu, Lizhen Qu, George\n",
      "Foster, and Gholamreza Haffari. 2024a. Adapt-\n",
      "ing large language models for document-\n",
      "level machine translation.\n",
      "arXiv preprint\n",
      "arXiv:2401.06468.\n",
      "Minghao Wu, Yulin Yuan, Gholamreza Haffari,\n",
      "and Longyue Wang. 2024b. (perhaps) beyond\n",
      "human translation: Harnessing multi-agent col-\n",
      "laboration for translating ultra-long literary texts.\n",
      "arXiv preprint arXiv:2405.11804.\n",
      "Minghao Wu, Yulin Yuan, Gholamreza Haffari,\n",
      "and Longyue Wang. 2024c. (perhaps) beyond\n",
      "human translation: Harnessing multi-agent col-\n",
      "laboration for translating ultra-long literary texts.\n",
      "Haoran Xu, Young Jin Kim, Amr Sharaf, and\n",
      "Hany Hassan Awadalla. 2023. A paradigm shift\n",
      "in machine translation: Boosting translation per-\n",
      "formance of large language models.\n",
      "Liang Xu, Hai Hu, Xuanwei Zhang, Lu Li, Chen-\n",
      "jie Cao, Yudong Li, Yechen Xu, Kai Sun, Dian\n",
      "Yu, Cong Yu, et al. 2020.\n",
      "Clue: A chinese\n",
      "language understanding evaluation benchmark.\n",
      "arXiv preprint arXiv:2004.05986.\n",
      "Fanghua Ye, Mingming Yang, Jianhui Pang,\n",
      "Longyue Wang, Derek F. Wong, Emine Yilmaz,\n",
      "Shuming Shi, and Zhaopeng Tu. 2024. Bench-\n",
      "marking llms via uncertainty quantification.\n",
      "Lifan Yuan, Yangyi Chen, Ganqu Cui, Hongcheng\n",
      "Gao, Fangyuan Zou, Xingyi Cheng, Heng Ji,\n",
      "Zhiyuan Liu, and Maosong Sun. 2023. Revisit-\n",
      "ing out-of-distribution robustness in nlp: Bench-\n",
      "mark, analysis, and llms evaluations.\n",
      "Yue Zhang, Yafu Li, Leyang Cui, Deng Cai, Lemao\n",
      "Liu, Tingchen Fu, Xinting Huang, Enbo Zhao,\n",
      "Yu Zhang, Yulong Chen, et al. 2023. Siren’s\n",
      "song in the ai ocean: a survey on hallucina-\n",
      "tion in large language models. arXiv preprint\n",
      "arXiv:2309.01219.\n",
      "Zihao Zhao, Eric Wallace, Shi Feng, Dan Klein,\n",
      "and Sameer Singh. 2021. Calibrate before use:\n",
      "Improving few-shot performance of language\n",
      "models. In International conference on machine\n",
      "learning, pages 12697–12706. PMLR.\n",
      "Jie Zhu, Junhui Li, Yalong Wen, and Lifan Guo.\n",
      "2024.\n",
      "Benchmarking large language models\n",
      "on cflue–a chinese financial language under-\n",
      "standing evaluation dataset.\n",
      "arXiv preprint\n",
      "arXiv:2405.10542.\n",
      "A\n",
      "Expertise of Human Annotators\n",
      "To categorize translators into junior, medium, or\n",
      "senior levels, we have established a comprehensive\n",
      "set of criteria that take into account various factors\n",
      "indicative of a translator’s expertise and experience.\n",
      "These factors include the translator’s educational\n",
      "background, particularly the prestige of the insti-\n",
      "tution from which they graduated, as well as their\n",
      "length of service in the translation industry, the\n",
      "duration of their translation career, the number of\n",
      "translations completed, and any professional certifi-\n",
      "cations they have obtained. To ensure the ongoing\n",
      "competence of our translators, we conduct quar-\n",
      "terly assessments to evaluate their performance.\n",
      "\fFor instance, to be classified as a senior-level trans-\n",
      "lator, an individual must possess a minimum of\n",
      "ten years of translation experience, demonstrate\n",
      "exceptional proficiency by achieving a score of\n",
      "99% on our assessments, and hold the distinguished\n",
      "CATTI++ translation certification. By considering\n",
      "these stringent criteria, we aim to maintain a highly\n",
      "qualified and skilled pool of translators across all\n",
      "levels of expertise.\n",
      "B\n",
      "Annotation Requirements\n",
      "B.1\n",
      "Error Types\n",
      "Our annotation system is built upon the open-\n",
      "sourced doccano system 3. In Figure 5, we provide\n",
      "a screenshot of our annotation system. For each\n",
      "source sentence, outputs for different systems are\n",
      "given and the annotators can select spans of the text\n",
      "and annotate the error type and severity.\n",
      "C\n",
      "Detailed Explanation and Guidance for\n",
      "Each Error Types\n",
      "Our evaluation protocol largely follows the MQM\n",
      "criteria released by Unbabel4. We provide a de-\n",
      "tailed annotation manual for annotators, including\n",
      "an explanation for each error type as well as illus-\n",
      "trative examples for error types. It is included in\n",
      "the following:\n",
      "C.1\n",
      "Annotation Requirements\n",
      "The minimum unit that can be selected and anno-\n",
      "tated is a whole word, a whitespace, a punctuation\n",
      "mark, or an isolated character. In the following\n",
      "example, the version in French has an extra excla-\n",
      "mation mark, so it’s necessary to annotate it as a\n",
      "Punctuation error:\n",
      "[EN] Thank you very much.\n",
      "[FR] Merci beaucoup!\n",
      "Wrong\n",
      "selection\n",
      "→Merci\n",
      "[beau-\n",
      "coup!]PUNCTUATION\n",
      "Correct\n",
      "selection\n",
      "→Merci\n",
      "beau-\n",
      "coup[!]PUNCTUATION\n",
      "If the issue occurs in a multiword expression,\n",
      "you will need to select the whole expression; if, for\n",
      "example, an entire sentence was translated and it\n",
      "shouldn’t have been, you should select the entire\n",
      "sentence.\n",
      "3https://github.com/doccano/doccano\n",
      "4\n",
      "In the following example, we have an Unnatural\n",
      "Flow error:\n",
      "[EN] Hi, Mary here.\n",
      "[ES] Hola, Mary aquí.\n",
      "Wrong\n",
      "selection\n",
      "→\n",
      "Hola,\n",
      "[Mary\n",
      "aquí.]UNNATURAL FLOW\n",
      "Correct\n",
      "selection\n",
      "→\n",
      "Hola,\n",
      "[Mary\n",
      "aquí]UNNATURAL FLOW.\n",
      "C.2\n",
      "Error Types\n",
      "Accuracy\n",
      "• Mistranslation\n",
      "– Description: Translation does not accu-\n",
      "rately represent the source.\n",
      "– Example:\n",
      "[EN] It has to be done by the book.\n",
      "[FR] Il doit être fait [par le\n",
      "livre]MISTRANSLATION\n",
      "[Reason] The word-for-word trans-\n",
      "lation into French doesn’t work.\n",
      "• Addition\n",
      "– Description: Information not present in\n",
      "the source.\n",
      "– Example:\n",
      "[EN] That way you can be sure that\n",
      "you were the one who made the\n",
      "changes.\n",
      "[ES] Así puedes estar seguro de que\n",
      "fuiste tú quien hizo [todos ADDI-\n",
      "tIoN los cambios.\n",
      "[Reason] [Todos] (meaning ’all’ in\n",
      "Spanish) is not present in the source\n",
      "and it is incorrectly added in the\n",
      "target text.\n",
      "• MT Hallucination\n",
      "– Description: information that has noth-\n",
      "ing related to source; or gibberish; or\n",
      "repeats\n",
      "– Example:\n",
      "[EN] You can send us a follow-up\n",
      "email at this address [EMAIL].\n",
      "[ES] [Hágame saber si tiene al-\n",
      "guna otra pregunta]MT HALLUCI-\n",
      "NATION.]\n",
      "[Reason]: The Spanish translation\n",
      "\fFigure 5: A screenshot of the Doccano annotation system we use.\n",
      "reads please let me know if you\n",
      "have any other questions and it’s\n",
      "grammatically correct and fluent,\n",
      "but it has no relation at all with the\n",
      "source.]\n",
      "• Omission\n",
      "– Description: Missing content from the\n",
      "source.\n",
      "– Example:\n",
      "[EN] We do not have much informa-\n",
      "tion on this.\n",
      "[FR]\n",
      "Nous\n",
      "ne\n",
      "disposons\n",
      "pas\n",
      "[]\n",
      "OMISSION\n",
      "beaucoup\n",
      "d’informations à ce sujet.\n",
      "[Reason]:\n",
      "The French sentence\n",
      "requires the preposition [de] (dis-\n",
      "poser de).\n",
      "• Untranslated\n",
      "– Description: Not translated.\n",
      "– Example:\n",
      "[EN] How To Make Pizza Dough\n",
      "[FR] Comment faire de [Pizza\n",
      "Dough|UNTRANSLATED\n",
      "[Reason]: [Pizza Dough] is not a\n",
      "named entity and is untranslated in\n",
      "the French version.\n",
      "• Wrong Name Entity & Term\n",
      "– Description: Wrong usage of NE and\n",
      "Terminology.\n",
      "– Example:\n",
      "[EN] Dear Wiley,\n",
      "[IT]\n",
      "Gentile\n",
      "[Wilar\n",
      "WRONG\n",
      "NAMED ENTITY,\n",
      "[Reason]: The name in the Italian\n",
      "version doesn’t match the original.\n",
      "Fluency\n",
      "• Grammar\n",
      "– Description: Problems with grammar of\n",
      "target language.\n",
      "– Example:\n",
      "[EN] I understand that you want to\n",
      "check in online.\n",
      "[CS]\n",
      "chàpu,\n",
      "ze\n",
      "se\n",
      "chcete\n",
      "[odbavení]gRAMMaR online.\n",
      "[Reason]: Wrong part of speech\n",
      "makes the sentence ungrammatical\n",
      "in Czech.\n",
      "• Punctuation\n",
      "– Description: incorrect punctuation (for\n",
      "locale or style).\n",
      "– Example:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<img alt=\"Technology.Zh_En.Annotation-2\n",
      "EN\n",
      "Projects\n",
      "Start Annotation\n",
      "Y\n",
      "目\n",
      "圃\n",
      "1 of4001&lt;\n",
      "&gt;\n",
      "I&lt;\n",
      "Home\n",
      "原文：\n",
      "Progress\n",
      "Dataset\n",
      "如果轮胎气压低，就会显示此警告信息。车辆上的对应轮胎位置指示灯亮。详细信息请参考第8章的“轮胎气压监测系统（TPMS)&quot;部分。\n",
      "Total\n",
      "400\n",
      "Labels\n",
      "Complete\n",
      "133\n",
      "译文1:lIf thetirepressure is low,thiswarningmessagewillbe displayed.Thecorresponding tireposition indicatorlight on thevehicle\n",
      "Members\n",
      "·Wrong Name E...\n",
      "34%\n",
      "日\n",
      "Comments\n",
      "willilluminate.Fordetailed information,pleasereferto the&quot;TirePressure MonitoringSystem(TPMs)&quot;section inChapter8.\n",
      "Label Types\n",
      "Guideline\n",
      "译文2:lf the tire pressure is low,this warningmessage will be displayed.The corresponding tire position indicator light on the vehicle is\n",
      "山\n",
      "Metrics\n",
      "·Wrong Name E...\n",
      "Mistranslation (Minor)\n",
      "Punctuation (Minor)\n",
      "Spelling (Minor)\n",
      "Settings\n",
      "Wrong Name Entity&amp; Term (Minor)\n",
      "on.Formoreinformation,seethetirepressuremonitoringsystem（TPMS)sectioninChapter8.\n",
      "·Spelling (Mi...\n",
      "Omission (Minor)\n",
      "Inconsistent Style(Minor)\n",
      "·Punctuation ...\n",
      "Unnatural Flow\n",
      "Omission (Major)\n",
      "Grammar (Minor)\n",
      "译文3: In case of low tire pressure,this warning message will pop up and the indicator corresponding to the tire willbe on.See&quot;Tire\n",
      "WrongNameEntity&amp;Term(Major)\n",
      "Mistranslation (Major)\n",
      "Register (Minor)\n",
      "PressureMonitoringSystem(TPMS)&quot;SectioninChapter8fordetails.\n",
      "·Spelling (Mi...\n",
      "Grammar (Major)\n",
      "Register (Major)\n",
      "MT Hallucination (Major)\n",
      "Punctuation (Major)\n",
      "译文 4:If the tire pressure is low,a warning message willbe displayed, and the corresponding tire position indicator on the vehicle will\n",
      "·Wrong Name E...\n",
      "MT Hallucination (Minor)\n",
      "Untraslated (Minor)\n",
      "Inconsistent Style (Major)\n",
      "Spelling (Major)\n",
      "Addition (Major)\n",
      "Addition (Minor)\n",
      "译文5: lf the tire pressure is low,this warning message willbe displayed, and the corresponding tire indicator on the vehicle will light up.\n",
      "Untrasnalted (Major)\n",
      "Non-translation\n",
      "Pleasereferto&quot;TirePressureMonitoringSystem(TPMs)&quot;inChapter8fordetails.\n",
      "Key\n",
      "Value\n",
      "P!\n",
      "2001\n",
      "Comments src=\"#\" />\n",
      "\f[EN] Original copy of the Proof of\n",
      "Purchase or Invoice (not a screen-\n",
      "shot):\n",
      "[PT] C’opia original do com-\n",
      "provante\n",
      "de\n",
      "compra\n",
      "ou\n",
      "nota\n",
      "fiscal\n",
      "(não\n",
      "uma\n",
      "captura\n",
      "de\n",
      "tela)[.]PUNCTUATION\n",
      "[Reason]: There’s a period instead\n",
      "of a colon in the Brazilian Por-\n",
      "tuguese version of this sentence.\n",
      "• Spelling\n",
      "– Description: incorrect spelling or capital-\n",
      "ization.\n",
      "– Example:\n",
      "[EN] This sort of damage is not cov-\n",
      "ered under the warranty, but we will\n",
      "seek assistance from a higher sup-\n",
      "port and see what we can do regard-\n",
      "ing this issue.\n",
      "[IT] Questo tipo di danno non è cop-\n",
      "erto dalla garanzia, ma chiederò\n",
      "comunque aiuto ai responsabili\n",
      "dell’assistenza per capire che cosa\n",
      "[Zi]SPELLING può fare per quanto\n",
      "riguarda questo problema.\n",
      "[Reason]: There’s a typo in the\n",
      "sentence in Italian: the word [zi]\n",
      "should be [si] instead.\n",
      "• Register\n",
      "– Description: Wrong grammatical regis-\n",
      "ter (e.g., inappropriately informal pro-\n",
      "nouns).\n",
      "– Example:\n",
      "[EN] Wishing you a great day\n",
      "ahead.\n",
      "[DE]\n",
      "Ich\n",
      "wünsche\n",
      "[Ih-\n",
      "nen]REGISTER\n",
      "einen\n",
      "schönen\n",
      "Tag.\n",
      "[Reason]: The required register for\n",
      "the German translation is Informal\n",
      "but the pronoun [Inhen] is Formal.\n",
      "• Inconsistent Style\n",
      "– Description: internal inconsistency (not\n",
      "related to terminology).\n",
      "– Example:\n",
      "[EN] Please click on this link. [...]\n",
      "This link will expire in 24 hours.\n",
      "[NN]\n",
      "Klikk\n",
      "på\n",
      "denne\n",
      "[lenken].[...]Denne\n",
      "[linken]INCONSISTENCY\n",
      "ut-\n",
      "loper om 24 timer.\n",
      "[Reason]: Both [lenk] and [link]\n",
      "are correct in Norwegian, but in the\n",
      "same document, only one should be\n",
      "used. Note: this is a single error,\n",
      "not two\n",
      "• Unnatural Flow\n",
      "– Description: translations that are too lit-\n",
      "eral or sound unnatural.\n",
      "– Example:\n",
      "[EN] Zebras are ideal for animal\n",
      "matching.\n",
      "[DE]\n",
      "[Zebras\n",
      "sind\n",
      "ideal,\n",
      "um\n",
      "bestimmte\n",
      "Tiere\n",
      "zu\n",
      "finden]UNNATURAL FLOW.\n",
      "[Reason] The German translation\n",
      "sounds too literal, it reads like a\n",
      "translation, using the verb [finden]\n",
      "(finding) as a translation for match-\n",
      "ing. The verb matching should be\n",
      "translated as [detektieren] (detect)\n",
      "to read as if it was originally written\n",
      "in the target language: [Zebras sind\n",
      "ein ideales Beispiel zur Detektion\n",
      "von Wildtieren.]\n",
      "Other\n",
      "• Non-translation\n",
      "D\n",
      "Extra Details\n",
      "D.1\n",
      "Translation Prompt in Preliminary Study\n",
      "In two experiments, the translation prompt we use\n",
      "is as follows:\n",
      "• Please translate the following sentences from\n",
      "<SRC_LANG> to <TGT_LANG>. Ensure\n",
      "line alignment across the document while\n",
      "maintaining the fluency of overall translation.\n",
      "The prompt asks GPT4 to maintain the sentence\n",
      "alignment of the given document, so each sentence\n",
      "can be aligned back to its source sentence while be-\n",
      "ing translated at the document level. In practice, we\n",
      "find most times GPT4 can follow our instructions.\n",
      "\fOccasionally, it fails to keep the sentence structure\n",
      "of the document and merges some sentences in one\n",
      "row. In these cases, we manually split the merged\n",
      "sentences.\n",
      "D.2\n",
      "Model and Decoding\n",
      "For GPT-4, we use greedy search for decoding,\n",
      "to ensure the reproducibility of the results. For\n",
      "SeamlessM4T, we use the 2.3B version of seam-\n",
      "lessM4T_v2_large and adopt beam search with\n",
      "beam size 5.\n"
     ]
    }
   ],
   "source": [
    "docs = loader.load()\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "spiltter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 800,\n",
    "    chunk_overlap= 150,\n",
    "    separators=[\"\\n\\n\",\"\\n\",\".\",\" \"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='GPT-4 vs. Human Translators: A Comprehensive Evaluation of\\nTranslation Quality Across Languages, Domains, and Expertise Levels\\nJianhao Yan1,2∗\\nPingchuan Yan3∗\\nYulong Chen4∗\\nJudy Li5\\nXianchao Zhu5\\nYue Zhang2,6,\\x001 Zhejiang University\\n2 School of Engineering, Westlake University\\n3 University College London\\n4 University of Cambridge\\n5 Lan-Bridge Group\\n6 Institute of Advanced Technology, Westlake Institute for Advanced Study\\nelliottyan37@gmail.com\\nAbstract\\nThis study comprehensively evaluates the\\ntranslation quality of Large Language Mod-\\nels (LLMs), specifically GPT-4, against hu-\\nman translators of varying expertise lev-\\nels across multiple language pairs and do-\\nmains. Through carefully designed annota-\\ntion rounds, we find that GPT-4 performs\\ncomparably to junior translators in terms of'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='mains. Through carefully designed annota-\\ntion rounds, we find that GPT-4 performs\\ncomparably to junior translators in terms of\\ntotal errors made but lags behind medium\\nand senior translators. We also observe the\\nimbalanced performance across different lan-\\nguages and domains, with GPT-4’s transla-\\ntion capability gradually weakening from\\nresource-rich to resource-poor directions. In\\naddition, we qualitatively study the trans-\\nlation given by GPT-4 and human transla-\\ntors, and find that GPT-4 translator suffers\\nfrom literal translations, but human trans-\\nlators sometimes overthink the background\\ninformation. To our knowledge, this study\\nis the first to evaluate LLMs against human\\ntranslators and analyze the systematic differ-\\nences between their outputs, providing valu-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='is the first to evaluate LLMs against human\\ntranslators and analyze the systematic differ-\\nences between their outputs, providing valu-\\nable insights into the current state of LLM-\\nbased translation and its potential limitations.\\n1\\nIntroduction\\nRecent studies show that LLMs can serve as a\\nstrong translation system and a good substitute for\\nNMT models (Jiao et al., 2023a; Wang et al., 2023a;\\nEnis and Hopkins, 2024; Huang et al., 2023; Wu\\net al., 2024a; Hendy et al., 2023; Peng et al., 2023).\\nFor example, Jiao et al. (2023a) and Wang et al.\\n(2023a) find that GPT-4 can outperform commer-\\ncial machine translation systems via automatic and\\nhuman evaluations. Such impressive results have\\nhastened a wide range of applications, including\\nthe use of GPT-4 for literary translation (Wu et al.,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='hastened a wide range of applications, including\\nthe use of GPT-4 for literary translation (Wu et al.,\\n2024b).\\n∗These authors contributed equally to this work.\\nDespite their impressive capabilities, the nature\\nof LLM output compared to human translators\\nremains unclear.\\nThis raises two critical ques-\\ntions: (1) How do LLMs compare to human ex-\\nperts in translation quality? and (2) Are there\\nfundamental differences in their outputs? These\\ninquiries are particularly relevant in light of recent\\nresearch demonstrating significant distinctions be-\\ntween LLM-generated and human-generated texts\\nin general (Li et al., 2023; Bao et al., 2023). Such\\nfindings suggest that even if LLMs produce high-\\nquality translations, their outputs may possess\\nunique characteristics that distinguish them from'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='findings suggest that even if LLMs produce high-\\nquality translations, their outputs may possess\\nunique characteristics that distinguish them from\\nhuman-produced translations.\\nTo determine where LLMs fall within the spec-\\ntrum of human translation proficiency, which\\nranges from novice translators to seasoned profes-\\nsionals, we study the problem by taking the current\\nrepresentative LLM, i.e., GPT-4, and comparing\\nit against human translators with different exper-\\ntise. We first conduct a preliminary study compar-\\ning human translations against GPT-4 translations,\\nfinding that even experts cannot reach a consen-\\nsus on which translation is better. Given these\\nfindings, we take a finer-grained evaluation across\\ndifferent languages and domains, so that translation'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='findings, we take a finer-grained evaluation across\\ndifferent languages and domains, so that translation\\nquality can be better calibrated and systematic dif-\\nferences can be measured. Our evaluation covers\\nthree language pairs from resource-rich to resource-\\npoor, i.e., Chinese↔English, Russian↔English,\\nand Chinese↔Hindi, and three domains, i.e., News,\\nTechnology, and Biomedical. Given a source sen-\\ntence, we ask junior, medium, and senior trans-\\nlators and GPT-4 to generate the corresponding\\ntranslation in the target language. Then given each\\ntranslation pair, we hire independent expert annota-\\ntors to label the errors in the target sentence under\\nthe MQM schema (Freitag et al., 2021). We find\\nthat GPT-4 reaches a comparable performance to'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='tors to label the errors in the target sentence under\\nthe MQM schema (Freitag et al., 2021). We find\\nthat GPT-4 reaches a comparable performance to\\njunior translators in the perspective of total errors\\nmade, and lags behind senior ones with a consider-\\narXiv:2407.03658v1  [cs.CL]  4 Jul 2024\\n\\x0cable gap.\\nOur further analyses and qualitative studies show\\nthat there are imbalanced performances for differ-\\nent languages and domains. From resource-rich to\\nresource-poor directions, GPT-4’s translation capa-\\nbility gradually weakens. For resource-rich direc-\\ntions like Chinese↔English, GPT-4 performs com-\\nparably with junior translators and even close to\\nmedium translators, but in Chinese↔Hindi, it even\\nlags behind our baseline system. The weaknesses'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='parably with junior translators and even close to\\nmedium translators, but in Chinese↔Hindi, it even\\nlags behind our baseline system. The weaknesses\\nmentioned above are also general shortcomings of\\nlarge models and reflect that although large models\\nhave achieved universal translation with a focus\\non one language, translation between low-resource\\nlanguages remains a relative weakness.\\nTo our knowledge, we are the first to evaluate\\nLLMs against human translators and analyze the\\nsystematic differences between LLMs and human\\ntranslators.\\n2\\nRelated Work\\nBenchmarking LLMs\\nPrevious studies have\\nbenchmarked LLMs on various NLP tasks. Xu et al.\\n(2020) benchmark several LLMs on Chinese text,\\nevaluating their Chinese ability. Ye et al. (2024)\\nassess LLMs through Question Answering (QA),'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='(2020) benchmark several LLMs on Chinese text,\\nevaluating their Chinese ability. Ye et al. (2024)\\nassess LLMs through Question Answering (QA),\\nMMLU (Hendrycks et al., 2021), and other metrics.\\nFrom these tests, LLMs with larger scales are gen-\\nerally proved to be more accurate except for certain\\ntasks. Yuan et al. (2023) demonstrates that LLMs\\nperform well in long-context understanding and\\nare more capable with Out-of-Distribution, which\\nmeans LLMs have a certain degree of generaliza-\\ntion ability.\\nFurther to the MT field, Jiao et al. (2023b) find\\nthat GPT-4 performed competitively with other\\nSotA translation products. Wang et al. (2023a)\\nfurther investigated the capability of GPT-4 in\\ndocument-level translation, the results show that\\nGPT-4 performs better than commercial translation'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='further investigated the capability of GPT-4 in\\ndocument-level translation, the results show that\\nGPT-4 performs better than commercial translation\\nproducts and document NMT methods. Compared\\nto them, our work empirically shows that GPT-4 is\\ncomparable to junior human translators.\\nLLMs as Human Experts\\nDue to the great ca-\\npacities of GPT-4 over traditional NLP models,\\nresearchers have investigated and compared the\\nperformance of GPT-4 as human experts in mul-\\ntiple NLP tasks. Zhu et al. (2024) highlight that\\nGPT-4 and GPT-4-turbo show top performance on\\na Chinese financial language understanding task.\\nLiu et al. (2023b) find the LLMs can be benefi-\\ncial to biomedical NLP tasks. Goyal et al. (2022)\\ncompare GPT models with several summarization\\nmodels and humans, and find that GPT can gen-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='cial to biomedical NLP tasks. Goyal et al. (2022)\\ncompare GPT models with several summarization\\nmodels and humans, and find that GPT can gen-\\nerate summaries preferred by humans. In AI for\\neducation area, Nguyen and Allan (2024) show\\nGPT-4’s can provide teaching feedback for stu-\\ndents. Maloney et al. (2024) find that GPT-4 shows\\nclose performance compared with human partici-\\npants in coordination games. Siu (2023) show that\\nGPT-4 is comparable to humans on technical trans-\\nlation tasks. Bojic et al. (2023) find that GPT-4 can\\noutperform human experts on linguistic pragmatic\\ntasks. In clinical diagnostics, Han et al. (2023)\\nfind that GPT-4 can give comparable performance\\nto humans, and GPT-4v (vision version) can even\\noutperform human experts.\\nHuman Evaluation for MT\\n(Graham et al.,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='to humans, and GPT-4v (vision version) can even\\noutperform human experts.\\nHuman Evaluation for MT\\n(Graham et al.,\\n2013) first propose Direct Assessment (DA), which\\nuses a continuous score from 0 to 100 to repre-\\nsent the quality of a hypothesis. DA has been\\nadopted in WMT translation tasks for the past\\nfew years (Farhad et al., 2021; Kocmi et al., 2022,\\n2023). MQM (Lommel et al., 2014), the annota-\\ntion used in this paper, is another widely used an-\\nnotation scheme (Klubiˇcka et al., 2018; Rei et al.,\\n2020a). It requires the annotators to annotate the\\nerror span for each hypothesis and is shown to be\\nmore accurate and reliable than DA (Freitag et al.,\\n2021). Thus, it is utilized in the metrics tasks of\\n2022 and 2023 WMT challenges (Freitag et al.,\\n2022, 2023).\\nHuman Parity'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='2021). Thus, it is utilized in the metrics tasks of\\n2022 and 2023 WMT challenges (Freitag et al.,\\n2022, 2023).\\nHuman Parity\\nThe human parity for machine\\ntranslation systems is first claimed by (Hassan et al.,\\n2018), which describes a comparable performance\\non the WMT 2017 news translation task from Chi-\\nnese to English when compared to professional hu-\\nman translations. However, this claim is challenged\\nby the following research, raising concerns about\\nthe limited scope of human parity. These limita-\\ntions include the expertise of human evaluators (Fis-\\ncher and L¨\"aubli, 2020), the origin and quality of\\nsource sentences (Toral et al., 2018; Kim et al.,\\n2023), the limited scenario of comparison (Poibeau,\\n2022) and difficulty of translation (Graham et al.,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='2023), the limited scenario of comparison (Poibeau,\\n2022) and difficulty of translation (Graham et al.,\\n2020), indicating significant gaps between NMT\\nmodels and the professional translators. In this\\nwork, we evaluate whether the SOTA LLM GPT-\\n4 performs comparable to professional translators\\nand what differs between human translators and\\nLLMs. With the above lessons in mind, we address\\n\\x0cthese limitations by hiring expert annotators, avoid-\\ning target-origin source text, manually evaluating\\nsource sentences, and covering high-resource to\\nlow-resource language pairs and various domains.\\n3\\nPreliminary Study\\nThis section presents our preliminary study. We\\naim to first compare GPT-4 translations with hu-\\nman translations qualitatively, in a coarse manner.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='This section presents our preliminary study. We\\naim to first compare GPT-4 translations with hu-\\nman translations qualitatively, in a coarse manner.\\nOur comparison is simple and direct. We sample\\nhuman-translated texts and prompt GPT-4 to trans-\\nlate the same source sentence. Then, we ask expert\\nannotators to determine which translation is better.\\nParticularly, to have a quick overview of the qual-\\nities of human translations against GPT-4 transla-\\ntions, we first utilize COMET-QE1 to score our\\nin-house Chinese to English human-translated doc-\\numents, and select two documents with the highest\\nscore and the lowest score. Note that our in-house\\ntranslated documents are all translated by profes-\\nsional translators. In this way, we gather 40 pairs'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='translated documents are all translated by profes-\\nsional translators. In this way, we gather 40 pairs\\nof translations from professional translators and\\nGPT-4, respectively. Recent findings (Freitag et al.,\\n2021) have demonstrated that crowd-sourced hu-\\nman ratings are less reliable for high-quality MT\\nevaluation. Thus, we hire six expert annotators to\\ncompare the two translations and select the better\\ntranslations they find. We randomly shuffle the\\nGPT-4 and human translations to prevent annota-\\ntors from identifying GPT-4.\\nThe\\naverage\\nwin\\nrate\\nof\\nGPT\\nis\\n15.5/40 (36.25%).\\nIt looks like a clear win\\nfor human translators, but when delving deeper,\\nwe find that the expert annotators have a low\\nratio of agreement with each other. In Table 1,\\nmost annotators only agree with each other at'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='we find that the expert annotators have a low\\nratio of agreement with each other. In Table 1,\\nmost annotators only agree with each other at\\naround 60% (the baseline is 50%) of an agreed\\nwinner at each source sentence.\\nWe further\\nconduct a significance test and only annotator\\nB finds human translation significantly better\\nthan GPT’s translation and other annotators\\nhave high p-values. Given annotators’ expertise\\nand our task is straightforward, these results\\nindicate that even expert annotators find it difficult\\nto agree on which translation is better, and\\nGPT-generated translations might have different\\nadvantages against human-generated ones. These\\nresults motivate us to conduct a finer-grained and\\ncomprehensive evaluation to reveal the systematic'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='advantages against human-generated ones. These\\nresults motivate us to conduct a finer-grained and\\ncomprehensive evaluation to reveal the systematic\\ndifference between GPT-4 and human translations.\\n1Unbabel/wmt23-cometkiwi-da-xl\\nAnnotators\\nA\\nB\\nC\\nD\\nE\\nF\\nA\\n100.0\\n57.5\\n65.0\\n65.0\\n62.5\\n67.5\\nB\\n-\\n100.0\\n52.5\\n52.5\\n50.0\\n50.0\\nC\\n-\\n-\\n100.0\\n65.0\\n82.5\\n67.5\\nD\\n-\\n-\\n-\\n100.0\\n57.5\\n62.5\\nE\\n-\\n-\\n-\\n-\\n100.0\\n70.0\\nF\\n-\\n-\\n-\\n-\\n-\\n100.0\\np-value\\n1.000\\n0.038\\n0.268\\n0.081\\n0.154\\n0.875\\nTable 1: Ratio(%) of agreed winner across expert\\nannotators and significance p-value for binomial\\ntest. P-value < 0.05 denotes a significant difference\\nbetween GPT-4 and Human.\\n4\\nMain Experimental Setup\\nMotivated by the results from our preliminary\\nstudy, we conduct a comprehensive and fine-\\ngrained evaluation, for revealing the systematic'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='Motivated by the results from our preliminary\\nstudy, we conduct a comprehensive and fine-\\ngrained evaluation, for revealing the systematic\\ndifference between humans and GPTs. Specifically,\\nwe employed the widely recognized Multidimen-\\nsional Quality Metrics (MQM) framework (Lom-\\nmel et al., 2014) and compared human translators\\nwith varying levels of expertise to GPT-4. Our\\nevaluation spans multiple languages and domains,\\naiming to furnish broad insights into these compar-\\nisons.\\n4.1\\nData Collection\\nWe collect multilingual and multi-domain source\\nsentences. Our multilingual evaluation data con-\\ntains six language directions, covering high re-\\nsource to low resource, including English to Chi-\\nnese, Chinese to English, English to Russian, Rus-\\nsian to English, English to Hindi, and Hindi to'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='source to low resource, including English to Chi-\\nnese, Chinese to English, English to Russian, Rus-\\nsian to English, English to Hindi, and Hindi to\\nEnglish.\\nFor general domain Chinese⇔English and\\nEnglish⇔Russian, we sample source sentences\\nfrom test sets of WMT2023 and WMT2022, re-\\nspectively. For Chinese⇔Hindi, we extract source\\nnews text from public websites. For multi-domain\\nevaluation data, we evaluate two domains, i.e.,\\nbiomedical and technology and we evaluate Chi-\\nnese to English. The source sentences are extracted\\nnews texts from public websites. We ensure that\\nall sources are source language origin to avoid the\\neffect of translationese. We manually evaluate all\\nsource sentences for these tasks and ensure the\\nsource sentences are not too easy or too short. Fi-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='source sentences for these tasks and ensure the\\nsource sentences are not too easy or too short. Fi-\\nnally, each task contains 200 sentences, making our\\nevaluation a total of 1600 sentences.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='|Annotators|A B C D E F|\\n|---|---|\\n|A B C D E F|100.0 57.5 65.0 65.0 62.5 67.5 &amp;#45; 100.0 52.5 52.5 50.0 50.0 &amp;#45; &amp;#45; 100.0 65.0 82.5 67.5 &amp;#45; &amp;#45; &amp;#45; 100.0 57.5 62.5 &amp;#45; &amp;#45; &amp;#45; &amp;#45; 100.0 70.0 &amp;#45; &amp;#45; &amp;#45; &amp;#45; &amp;#45; 100.0|\\n|p&amp;#45;value|1.000 0.038 0.268 0.081 0.154 0.875|\\n\\x0cType\\nError Name\\nExplanations\\nAccuracy\\nMistranslation\\nTranslation does not accurately represent the source.\\nAddition\\nInformation not present in the source.\\nMT Hallucination\\nInformation that has nothing related to source; or gibber-\\nish; or repeats\\nOmission\\nMissing content from the source.\\nUntranslated\\nNot translated.\\nWrong Name Entity and Term\\nWrong usage of NE and Terminology.\\nFluency\\nGrammar'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='Omission\\nMissing content from the source.\\nUntranslated\\nNot translated.\\nWrong Name Entity and Term\\nWrong usage of NE and Terminology.\\nFluency\\nGrammar\\nProblems with grammar of target language.\\nPunctuation\\nIncorrect punctuation (for locale or style)\\nSpelling\\nIncorrect spelling or capitalization.\\nRegister\\nWrong grammatical register (e.g., inappropriately infor-\\nmal pronouns).\\nInconsistent Style\\nInternal inconsistency ( not related to terminology )\\nUnnatural Flow\\nTranslations that are too literal or sound unnatural.\\nOther\\nNon-translation\\n-\\nTable 2: Error category and explanations. We mainly follow the guidelines from Unbabel, and merge some\\nerrors to reduce the efforts for annotators to understand the annotation system. Concrete examples for\\neach error category can be found in the Appendix.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='each error category can be found in the Appendix.\\n4.2\\nHuman Translators and Machine\\nTranslators\\nWe ask different human translators to translate our\\nsource sentences into the target language. Transla-\\ntors are of three different levels of expertise, cate-\\ngorized into junior-level, medium-level, and senior-\\nlevel translators. The level of expertise is ranked\\nby in-house criteria covering the translators’ edu-\\ncational background, translation experience, and\\npractical proficiency. See Appendix A for more de-\\ntails. For a fair comparison, we request the experts\\nnot use machine translation or GPTs as assistance.\\nFor all directions except Zh-Hi and Hi-Zh, we col-\\nlect three human translation results from each level\\nof expertise. For Zh-Hi and Hi-Zh, we only have'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='lect three human translation results from each level\\nof expertise. For Zh-Hi and Hi-Zh, we only have\\nmedium-level and senior-level translators due to\\nthe scarcity of translators.\\nExcept\\nfor\\nhuman\\ntranslators,\\nwe\\nuse\\ngpt-4-1106-preview,\\nthe\\ncurrent\\nstate-\\nof-the-art large language model released by\\nOpenAI and Seamless M4T (Communication\\net al., 2023) as the representative of traditional ma-\\nchine translations to complement our experiments.\\nWe directly prompt GPT-4 to obtain the translation,\\nas it is the most common practice for normal users,\\nthe easiest to reproduce, and to avoid confusion by\\nvarious techniques.\\n4.3\\nPrompt Search\\nPrevious study (Zhao et al., 2021; Liu et al., 2023a)\\nshows that different prompts with LLMs can result\\nin distinctive performance. Thus, we collect three'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='shows that different prompts with LLMs can result\\nin distinctive performance. Thus, we collect three\\ncandidate prompts used in previous research (Xu\\net al., 2023; Jiao et al., 2023a) and use COMET-\\nQE (Rei et al., 2020b) to select the best prompt\\nto make the best use of GPT-4, as shown in Table\\n3. In particular, we use these three prompts to\\nprompt GPT-4 to translate 100 source sentences in\\nour Chinese-to-English test set and adopt COMET-\\nQE to evaluate the quality of translations. We find\\nthat the third prompt yields the best performance,\\nand hence we adopt this prompt for all following\\nexperiments.\\n4.4\\nAnnotation Protocol\\nTo evaluate the results of candidates’ systems,\\nwe hire experts to annotate the errors of trans-\\nlations blindly. The annotation platform is Doc-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='To evaluate the results of candidates’ systems,\\nwe hire experts to annotate the errors of trans-\\nlations blindly. The annotation platform is Doc-\\ncano (Nakayama et al., 2018), and the error tags\\nare made according to MQM standards. MQM\\nrequires the annotators to annotate the span of er-\\nrors in each hypothesis. All hypotheses of the same\\nsource sentence are shown to the annotator together\\nto help decide which is better. We have 13 error\\ncategories and two severities, as shown in Table\\n2. Our categorization for errors mostly follows'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='|Type|Error Name|Explanations|\\n|---|---|---|\\n|Accuracy|Mistranslation|Translation does not accurately represent the source.|\\n||Addition|Information not present in the source.|\\n||MT Hallucination|Information that has nothing related to source; or gibber&amp;#45; ish; or repeats|\\n||Omission|Missing content from the source.|\\n||Untranslated|Not translated.|\\n||Wrong Name Entity and Term|Wrong usage of NE and Terminology.|\\n|Fluency|Grammar|Problems with grammar of target language.|\\n||Punctuation|Incorrect punctuation (for locale or style)|\\n||Spelling|Incorrect spelling or capitalization.|\\n||Register|Wrong grammatical register (e.g., inappropriately infor&amp;#45; mal pronouns).|\\n||Inconsistent Style|Internal inconsistency ( not related to terminology )|'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='||Inconsistent Style|Internal inconsistency ( not related to terminology )|\\n||Unnatural Flow|Translations that are too literal or sound unnatural.|\\n|Other|Non&amp;#45;translation|&amp;#45;|\\n\\x0cPrompt\\nCOMET\\nPlease translate the following sen-\\ntence from Chinese into English.\\nYour language and style should align\\nwith the language conventions of a\\nnative speaker. \\\\n{SOURCE}\\\\n\\n0.775\\nYou are an expert translator for trans-\\nlating Chinese to English.\\nYour\\nlanguage and style should align\\nwith the language conventions of\\na native speaker.\\n\\\\n[Chinese]:\\n{SOURCE}\\\\n[English]:\\n0.755\\nPlease provide the English transla-\\ntion for these sentences. Your lan-\\nguage and style should align with\\nthe language conventions of a native\\nspeaker. \\\\n{SOURCE}\\\\n\\n0.780\\nTable 3: Taking Chinese to English as an example,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='guage and style should align with\\nthe language conventions of a native\\nspeaker. \\\\n{SOURCE}\\\\n\\n0.780\\nTable 3: Taking Chinese to English as an example,\\nour three prompts and corresponding scores with\\nCOMET-QE. {SOURCE} represents the source sen-\\ntence to be translated.\\nUnbabel’s practice 2 and we focus on most com-\\nmon error types. Each tag has subtags with two\\nseverities, i.e., Minor or Major. A screenshot of the\\nannotation system is given in Figure 5.\\nFor each task, we first ask the two expert anno-\\ntators to carefully read our manual and conduct\\na training round on the first 10 groups of transla-\\ntions. Then, we manually check these annotations\\nto provide feedback and ask the two annotators to\\ncheck their disagreements and revise their results.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='to provide feedback and ask the two annotators to\\ncheck their disagreements and revise their results.\\nAfter two rounds of such training processes, we\\nask the annotators to finish the remaining sentences\\nwithout knowing each other’s results.\\nAfter the first round of annotation, we conduct a\\nsecond round to further refine the evaluation results.\\nIn particular, we hire another two experts for each\\ntask and show them the previous annotation results.\\nThey are asked to approve and make necessary\\nmodifications to previous round annotations.\\n4.5\\nInter-Annotator Agreement\\nError annotation with MQM is challenging, and\\nprevious work demonstrates that the agreement\\nscores between MQM annotations are relatively\\nlow (Lommel et al., 2014). Reasons for this could'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='previous work demonstrates that the agreement\\nscores between MQM annotations are relatively\\nlow (Lommel et al., 2014). Reasons for this could\\nbe disagreement on precise spans and ambiguous\\n2https://help.unbabel.\\ncom/hc/en-us/articles/\\n6444304419479-Annotation-Guidelines-Typology-3-0\\nTask\\nCohen Kappa(Segment)\\nKrippendorffs(Span)\\nReference, Re-Annotated by (Freitag et al., 2021)\\nWMT 2020 En-De\\n0.208\\n0.456\\nWMT 2021 En-De\\n0.230\\n0.501\\nOurs\\nGeneral Zh-En\\n0.257\\n0.436\\nGeneral En-Zh\\n0.544\\n0.579\\nGeneral En-Ru\\n0.461\\n0.566\\nGeneral Ru-En\\n0.341\\n0.875\\nGeneral Zh-Hi\\n0.256\\n0.443\\nGeneral Hi-Zh\\n0.234\\n0.495\\nTechnology Zh-En\\n0.306\\n0.581\\nBiomedical Zh-En\\n0.373\\n0.616\\nAverage\\n0.321\\n0.555\\nTable 4: Cohen Kappa (segment-level) and Krip-\\npendorffs’ Alpha (span-level) agreement of our an-\\nnotations.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='0.373\\n0.616\\nAverage\\n0.321\\n0.555\\nTable 4: Cohen Kappa (segment-level) and Krip-\\npendorffs’ Alpha (span-level) agreement of our an-\\nnotations.\\nerror categorization (Lommel et al., 2014). Despite\\nthe low agreement scores, MQM is more reliable\\nthan other evaluation protocols like Direct Assess-\\nment (Freitag et al., 2021).\\nTo compute inter-annotator agreement for MQM,\\nwe employ segment-level Cohen’s Kappa (Cohen,\\n1960) and span-level Krippendorff’s alpha (Krip-\\npendorff, 1980). For reference, we calculate the\\nagreement on the annotated results of the 2020 and\\n2021 WMT English-to-German tasks by (Freitag\\net al., 2021). Our IAA results are shown in Table 4.\\nThanks to our two-round annotation process, our\\nIAA scores show a favorable agreement, indicating\\na good annotation quality.\\n5\\nMain Results'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='Thanks to our two-round annotation process, our\\nIAA scores show a favorable agreement, indicating\\na good annotation quality.\\n5\\nMain Results\\n5.1\\nOverall Results\\nAnalysis of Error Severity\\nThe upper part of\\nFigure 1 plots the averaged number of errors of\\ndifferent systems and translators. Compared to our\\nMT baseline (seamless), GPT-4 has much fewer er-\\nrors. It performs almost as well as the junior-level\\ntranslator at the level of total errors, as GPT-4 is\\nannotated with only slightly more minor and major\\nerrors than junior translators. However, GPT-4 still\\nhas clear performance gaps between medium or\\nsenior human translators, as it makes considerably\\nmore mistakes than experienced translators. To our\\nknowledge, we are the first to report how GPT-4 is'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='more mistakes than experienced translators. To our\\nknowledge, we are the first to report how GPT-4 is\\non translation against human translators.\\nAnalysis of Error Categories\\nFurthermore, we\\nplot the categories of errors in the bottom part of\\nFigure 1. Compared with junior human translators,\\nGPT-4 makes more errors in the accuracy of trans-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='|Prompt|COMET|\\n|---|---|\\n|Please translate the following sen&amp;#45; tence from Chinese into English. Your language and style should align with the language conventions of a native speaker. \\\\n{SOURCE}\\\\n|0.775|\\n|You are an expert translator for trans&amp;#45; lating Chinese to English. Your language and style should align with the language conventions of a native speaker. \\\\n[Chinese]: {SOURCE}\\\\n[English]:|0.755|\\n|Please provide the English transla&amp;#45; tion for these sentences. Your lan&amp;#45; guage and style should align with the language conventions of a native speaker. \\\\n{SOURCE}\\\\n|0.780|'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='|Task|Cohen Kappa(Segment)|Krippendorffs(Span)|\\n|---|---|---|\\n|Reference, Re&amp;#45;Annotated by (Freitag et al., 2021)|||\\n|WMT 2020 En&amp;#45;De|0.208|0.456|\\n|WMT 2021 En&amp;#45;De|0.230|0.501|\\n|Ours|||\\n|General Zh&amp;#45;En|0.257|0.436|\\n|General En&amp;#45;Zh|0.544|0.579|\\n|General En&amp;#45;Ru|0.461|0.566|\\n|General Ru&amp;#45;En|0.341|0.875|\\n|General Zh&amp;#45;Hi|0.256|0.443|\\n|General Hi&amp;#45;Zh|0.234|0.495|\\n|Technology Zh&amp;#45;En|0.306|0.581|\\n|Biomedical Zh&amp;#45;En|0.373|0.616|\\n|Average|0.321|0.555|\\n\\x0cseamless\\ngpt4\\njunior\\nmedium\\nsenior\\nSystems\\n0\\n50\\n100\\n150\\n200\\nNumber of Errors\\nAverage Severity for Each System\\nMinor\\nMajor\\nseamless\\ngpt4\\njunior\\nmedium\\nsenior\\nSystems\\n0\\n25\\n50\\n75\\n100\\n125\\n150\\n175\\n200\\nNumber of Errors\\nError Category for Each System\\nAccuracy\\nFluency'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='Major\\nseamless\\ngpt4\\njunior\\nmedium\\nsenior\\nSystems\\n0\\n25\\n50\\n75\\n100\\n125\\n150\\n175\\n200\\nNumber of Errors\\nError Category for Each System\\nAccuracy\\nFluency\\nFigure 1: Upper: Error severity for each system.\\nThe gray line represents the standard deviation for\\neach system across tasks. Bottom: Error category\\nanalysis for each system.\\nlations, which accounts for most of the disparity.\\nInterestingly, GPT-4 surpasses junior translators\\nin fluency issues, denoting a better capability of\\nlanguage usage.\\nIn addition, Figure 2 shows the top 5 categories\\nof errors made by different systems. ‘Mistransla-\\ntion’ is the most frequent error made by all systems.\\nImproving much over the seamless baseline, GPT-\\n4 makes comparable numbers of ‘Mistranslation’\\nwith junior and medium human translators.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='Improving much over the seamless baseline, GPT-\\n4 makes comparable numbers of ‘Mistranslation’\\nwith junior and medium human translators.\\nFor all translators, ‘Unnatural Flow’ is among\\nthe most frequent errors. Seamless, GPT-4, and\\njunior translators have similar levels of ‘Unnatural\\nFlow’, indicating possible issues of literal transla-\\ntion and not following language conventions. In\\ncontrast, medium and senior translators are anno-\\ntated with significantly fewer errors of ‘Unnatural\\nFlow’.\\nIn addition, we notice even though GPT-4 makes\\nMistranslation\\nPunctuation\\nWrong NE\\nUnnatural Flow\\nOmission\\nMistranslation\\nUnnatural Flow\\nWrong NE\\nGrammar\\nPunctuation\\nMistranslation\\nUnnatural Flow\\nGrammar\\nWrong NE\\nPunctuation\\nMistranslation\\nUnnatural Flow\\nWrong NE\\nOmission\\nGrammar\\nMistranslation'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='Grammar\\nPunctuation\\nMistranslation\\nUnnatural Flow\\nGrammar\\nWrong NE\\nPunctuation\\nMistranslation\\nUnnatural Flow\\nWrong NE\\nOmission\\nGrammar\\nMistranslation\\nUnnatural Flow\\nAddition\\nPunctuation\\nGrammar\\n0\\n10\\n20\\n30\\n40\\n50\\n60\\n70\\n80\\nNumber of Errors\\nTop5 Error Categories\\nseamless\\ngpt4\\njunior\\nmedium\\nsenior\\nFigure 2: Top 5 categories of errors made by each\\nsystem.\\nmuch fewer ‘Wrong Name Entity(NE)’ errors com-\\npared to Seamless, which could be beneficial be-\\ncause of its huge knowledge acquired in the pre-\\ntraining stage, it still has a gap compared to human\\ntranslators.\\nFinally, we notice that GPT-4 does not have\\nOmission or Addition problems in its top-5 errors,\\nwhereas even senior translators have Addition er-\\nrors.\\n5.2\\nDetailed Results for Each Language'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='Omission or Addition problems in its top-5 errors,\\nwhereas even senior translators have Addition er-\\nrors.\\n5.2\\nDetailed Results for Each Language\\nIn Figure 3, we present detailed results for each\\nlanguage pair, averaged over two directions.\\nEnglish-Chinese\\nFrom Figure 3(a),\\nGPT-4\\nshows the great capability of translating English\\nto Chinese and vice versa. From the radar chart,\\nwe can see that GPT-4 makes almost the same or\\nslightly fewer semantic errors (Omission, Addition,\\nand Mistranslation errors) than Junior and Senior\\ntranslators. Especially mistranslation errors, which\\nare generally considered most semantically detri-\\nmental, are better than junior and senior translators.\\nFor omission and addition errors, GPT-4 reaches al-\\nmost the same level as senior translators. However,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='For omission and addition errors, GPT-4 reaches al-\\nmost the same level as senior translators. However,\\nGPT-4 made significantly more lexical, stylistic,\\nand grammatical errors than human translators do.\\nThe error distribution of translation of GPT-4 meets\\nour expectations, as in the absence of reference,\\nGPT-4 will translate unfamiliar words directly and\\nliterally instead of seeking online materials or other\\nforms of help like human translators. Furthermore,\\ndue to the complexity and variability of Chinese,\\nthe translation of entity names or proper nouns is\\nusually not one-to-one, two above reasons together'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='|Average Severity for Each System Minor|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|Col10|Col11|Col12|Col13|Minor|Col15|\\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\\n|Minor Major|||||||||||||Minor Major||\\n||||||||||||||||\\n||||||||||||||||\\n||||||||||||||||\\n||||||||||||||||\\n||||||||||||||||\\n||||||||||||||||\\n||||||||||||||||\\n||||||||||||||||\\n\\n\\n|Top5 Error Categories|Col2|Col3|Col4|Col5|seamless|\\n|---|---|---|---|---|---|\\n||||||seamless|\\n||||||gpt4 junior medium|\\n||senior||||senior|\\n|||||||\\n|||||||\\n|||||||\\n|||||||\\n|||||||\\n|||||||'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='|Error Category for Each System|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|Col10|Col11|Col12|Col13|Col14|Col15|Col16|Col17|\\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\\n||||||||||||||Accuracy Fluency||||\\n||||||||||||||||||\\n||||||||||||||||||\\n||||||||||||||||||\\n||||||||||||||||||\\n||||||||||||||||||\\n||||||||||||||||||\\n||||||||||||||||||\\n||||||||||||||||||\\n||||||||||||||||||\\n||||||||||||||||||\\n||||||||||||||||||\\n||||||||||||||||||\\n||||||||||||||||||\\n\\x0cMistranslation(130)\\nAddition(4)\\nMT Hallucination(14)\\nOmission(29)\\nUntranslated(0)\\nWrong Name Entity & Term(78)\\nGrammar(9)\\nPunctuation(11)\\nSpelling(4)\\nRegister(8)\\nInconsistent Style(0)\\nNon-translation(0)\\nUnnatural Flow(0)\\n0.0 0.2 0.4 0.6 0.8 1.0\\nseamless\\ngpt4\\njunior\\nmedium\\nsenior\\n(a) Chinese↔English\\nMistranslation(20)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='Non-translation(0)\\nUnnatural Flow(0)\\n0.0 0.2 0.4 0.6 0.8 1.0\\nseamless\\ngpt4\\njunior\\nmedium\\nsenior\\n(a) Chinese↔English\\nMistranslation(20)\\nAddition(8)\\nMT Hallucination(0)\\nOmission(17)\\nUntranslated(2)\\nWrong Name Entity & Term(1)\\nGrammar(5)\\nPunctuation(3)\\nSpelling(3)\\nRegister(0)\\nInconsistent Style(3)\\nNon-translation(0)\\nUnnatural Flow(0)\\n0.0\\n0.2\\n0.4\\n0.6\\n0.8\\n1.0\\nseamless\\ngpt4\\njunior\\nmedium\\nsenior\\n(b) English↔Russian\\nMistranslation(52)\\nAddition(6)\\nMT Hallucination(5)\\nOmission(9)\\nUntranslated(6)\\nWrong Name Entity & Term(7)\\nGrammar(6)\\nPunctuation(10)\\nSpelling(3)\\nRegister(1)\\nInconsistent Style(1)\\nNon-translation(0)\\nUnnatural Flow(0)\\n0.0\\n0.2\\n0.4\\n0.6\\n0.8\\n1.0\\nseamless\\ngpt4\\nmedium\\nsenior\\n(c) Chinese↔Hindi'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='Register(1)\\nInconsistent Style(1)\\nNon-translation(0)\\nUnnatural Flow(0)\\n0.0\\n0.2\\n0.4\\n0.6\\n0.8\\n1.0\\nseamless\\ngpt4\\nmedium\\nsenior\\n(c) Chinese↔Hindi\\nFigure 3: Error category results for each language. Each sub-figure is the average over two directions.\\nWe only include ‘Major’ errors here to highlight the most severe problems. Higher values indicate more\\nerrors and the number after each error type is the maximum number of that error.\\ncause the inferiority of the performance of GPT-4\\nin these aspects.\\nEnglish-Russian\\nFor the English-Russian trans-\\nlation tasks, GPT-4 made slightly more semantic\\nerrors but the number of mistranslation errors made\\nby GPT-4 is almost at the same level as medium\\nand senior translators. However, GPT-4 generally\\nmade less stylistic, grammatical, and wrong name'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='by GPT-4 is almost at the same level as medium\\nand senior translators. However, GPT-4 generally\\nmade less stylistic, grammatical, and wrong name\\nentity & term than junior translators. The English-\\nRussian translation tasks are quite challenging and\\nthe performance of translators varies significantly,\\nbut GPT-4 still maintains the average level overall.\\nHindi-Chinese\\nAs the low-resource language\\npair we evaluate, GPT-4 demonstrates the worst\\nperformance across evaluated translators. We ob-\\nserve that GPT4 is inferior to our MT baseline. This\\nmay be due to the small portion of Hindi and Chi-\\nnese corpora in its pre-training dataset. Specifically,\\nmaking the most ‘Mistranslation’ errors of GPT-4\\nindicates a distance away from the language under-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='making the most ‘Mistranslation’ errors of GPT-4\\nindicates a distance away from the language under-\\nstanding of human translators. As a comparison,\\nSeamlessM4T performs better in both semantic and\\nlexical errors.\\nDiscussion\\nOur results here manifest an imbal-\\nance of multilinguality for LLMs (Wang et al.,\\n2023b). Our results imply that GPT-4 can serve\\nas a reliable translator for resource-high such as\\nChinese to English but is doubtful for low-resource\\ndirections like Chinese-Hindi. In the low-resource\\nscenario, machine translator is more reliable.\\n5.3\\nDetailed Results for Different Domains\\nFigure 4 presents our results for different domains\\nin Chinese-to-English translation. We compare\\nthree different domains, including news, technol-\\nogy, and biomedical.\\nGeneral News Domain'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='in Chinese-to-English translation. We compare\\nthree different domains, including news, technol-\\nogy, and biomedical.\\nGeneral News Domain\\nGPT-4 performs worse\\nin the news domain than human translators of three\\nlevels. The number of semantic errors made by\\nGPT-4 is quite close to junior and medium transla-\\ntors. Nonetheless, GPT-4 made more lexical and\\ngrammatical errors compared to human translators.\\nWe hypothesize the reasons for the situation de-\\nscribed above to happen are mainly because of the\\nliterariness and timeliness. Because GPT-4 is not\\nable to access the online materials to confirm the\\nname of a specific entity or event.\\nTechnology Domain\\nThe performance of GPT-4\\nis relatively close to medium-level translators. Ex-\\ncept for the Wrong Name Entity & Terms, GPT-4'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='Technology Domain\\nThe performance of GPT-4\\nis relatively close to medium-level translators. Ex-\\ncept for the Wrong Name Entity & Terms, GPT-4\\nmakes almost the same or even fewer errors than\\nmedium-level translators across all aspects. Specif-\\nically, the number of semantic errors made by GPT-\\n4 is almost the same to medium-level translators\\nand it makes much fewer structural and grammati-\\ncal errors. It means that in this field, GPT-4 might\\nunderstand the original text better than junior or\\nmedium-level translators and be able to conduct\\na translation that is more in line with the original\\nmeaning.\\nBiomedical Domain\\nSimilar to the technology\\ndomain, the qualities of the translations made by\\nGPT-4 and medium-level translators stand at the\\n\\x0cMistranslation(105)\\nAddition(4)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='domain, the qualities of the translations made by\\nGPT-4 and medium-level translators stand at the\\n\\x0cMistranslation(105)\\nAddition(4)\\nMT Hallucination(2)\\nOmission(27)\\nUntranslated(0)\\nWrong Name Entity & Term(75)\\nGrammar(9)\\nPunctuation(7)\\nSpelling(2)\\nRegister(6)\\nInconsistent Style(0)\\nNon-translation(0)\\nUnnatural Flow(0)\\n0.0 0.2 0.4 0.6 0.8 1.0\\nseamless\\ngpt4\\njunior\\nmedium\\nsenior\\n(a) General news domain.\\nMistranslation(114)\\nAddition(3)\\nMT Hallucination(2)\\nOmission(57)\\nUntranslated(0)\\nWrong Name Entity & Term(157)\\nGrammar(30)\\nPunctuation(9)\\nSpelling(3)\\nRegister(8)\\nInconsistent Style(5)\\nNon-translation(0)\\nUnnatural Flow(0)\\n0.0 0.2 0.4 0.6 0.8 1.0\\nseamless\\ngpt4\\njunior\\nmedium\\nsenior\\n(b) Technology domain.\\nMistranslation(21)\\nAddition(0)\\nMT Hallucination(3)\\nOmission(9)\\nUntranslated(0)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='seamless\\ngpt4\\njunior\\nmedium\\nsenior\\n(b) Technology domain.\\nMistranslation(21)\\nAddition(0)\\nMT Hallucination(3)\\nOmission(9)\\nUntranslated(0)\\nWrong Name Entity & Term(49)\\nGrammar(0)\\nPunctuation(2)\\nSpelling(1)\\nRegister(0)\\nInconsistent Style(0)\\nNon-translation(0)\\nUnnatural Flow(0)\\n0.0\\n0.2\\n0.4\\n0.6\\n0.8\\n1.0\\nseamless\\ngpt4\\njunior\\nmedium\\nsenior\\n(c) Biomedical domain.\\nFigure 4: Error category results for different domains in Chinese-to-English. We only include ‘Major’\\nerrors here to highlight the most severe problems. Higher values indicate more errors and the number in\\nthe bracket is the maximum number of that error.\\nSource\\n巨人网络有限公司\\nGPT-4\\nGiant Network Group Inc.\\nHuman\\nGiant Interactive Group Inc.\\nTable 5: Named Entity cases.\\nsame level. Despite slightly more Wrong Name'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='巨人网络有限公司\\nGPT-4\\nGiant Network Group Inc.\\nHuman\\nGiant Interactive Group Inc.\\nTable 5: Named Entity cases.\\nsame level. Despite slightly more Wrong Name\\nEntity & Terms errors made, GPT-4 performs better\\nthan junior and medium-level translators in other\\naspects.\\nDiscussion\\nFor specific domains like technol-\\nogy, we show that GPT-4 is comparable with ju-\\nnior/medium translators. We still notice a similar\\nimbalance issue as in the multilingual setting, but\\nGPT-4’s performance is not as sensitive as in the\\nchange of language.\\n5.4\\nCase Study\\nWe also qualitatively understand the difference be-\\ntween the translations given by GPT-4 and human\\ntranslators.\\nLiteral Translations\\nAmong the error cases, the\\ntypical one is literal translations. Specifically, we'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='translators.\\nLiteral Translations\\nAmong the error cases, the\\ntypical one is literal translations. Specifically, we\\nfind that GPT-4 sometimes translates with semanti-\\ncally correct, but in-native and literal translations.\\nThis is problematic with named entities, especially\\nthose occurring less frequently. As shown in Table\\n5, when not knowing the correct translation of ‘巨\\n人网络有限公司’, GPT-4 translates the term word\\nby word. However, the issue of name entities oc-\\ncurs less for human translators, partially because\\nthey would google it to find the correct translation.\\nSource\\nIt’s just a white screen or it times out load-\\ning it, or the page becomes unresponsive!\\nGPT-4\\n它只是一个白屏，要么是加载时超时，\\n要么页面变得无响应了！\\nHuman\\n页面要么显示空白，要么加载超时或是\\n无响应。\\nTable 6: Unnatural-Flow cases. Red represents the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='GPT-4\\n它只是一个白屏，要么是加载时超时，\\n要么页面变得无响应了！\\nHuman\\n页面要么显示空白，要么加载超时或是\\n无响应。\\nTable 6: Unnatural-Flow cases. Red represents the\\nliteral translation and green is more natural and\\nnative in Chinese.\\nThus, this issue might be resolved by incorporating\\nweb-search into agent-like translation (Feng et al.,\\n2024; Wu et al., 2024c).\\nExcept for named entities, we notice that the\\nliteral translation causes Unnatural Flows.\\nAs\\nshown in Table 6, when translating ‘It’s just a white\\nscreen’, GPT-4 translates the phrase to ‘它(it)只\\n是(is just)一个(a)白屏(white screen)’, but human\\ntranslator translates this phrase to ‘‘页面显示空\\n白(The page display is white)’’, which represents\\na preciser meaning and follows local conventions.\\nHuman Imagination\\nWe find human translators\\nalso have drawbacks compared to the GPT-4 trans-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='a preciser meaning and follows local conventions.\\nHuman Imagination\\nWe find human translators\\nalso have drawbacks compared to the GPT-4 trans-\\nlator. When the source sentence contains insuffi-\\ncient information to translate, human translators\\ntend to fill the gap by imagination or overthinking.\\nAn example is given in Table 7. The translator\\nwrongly understands the phrase ‘entering his 2nd\\nyear’ as Daley is a two-year-old baby, but the sen-\\ntence describes a 2nd-year player for sports. This\\nmay be due to daily language habits, misunder-\\n\\x0cSource\\nHe\\nhas\\nhealth\\nconcerns\\natm\\nbut\\nwe also have Daley entering his 2nd year\\nand is a decent safety net.\\nGPT-4\\n他目前有健康问题，但我们还有戴利进\\n入他的第二年，他是一个不错的安全保\\n障。\\nHuman\\n他目前有健康问题。不过，戴利两岁\\n了，是个不错的备选人。\\nTable 7: Human imagination cases. Red denotes the\\nimagined part.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='GPT-4\\n他目前有健康问题，但我们还有戴利进\\n入他的第二年，他是一个不错的安全保\\n障。\\nHuman\\n他目前有健康问题。不过，戴利两岁\\n了，是个不错的备选人。\\nTable 7: Human imagination cases. Red denotes the\\nimagined part.\\nstanding, or not paying attention, and could be\\nrelated to the hallucination (Zhang et al., 2023) of\\nLLMs. GPT-4’s literal translation helps in this, as\\nit keeps faithful to the source sentence. This also\\naligns with our findings in Section 5.1 that GPT-4\\nhas fewer Additions or Omissions.\\n6\\nConclusion\\nIn this study, we comprehensively evaluated the\\ntranslation quality of GPT-4 against human trans-\\nlators of varying expertise levels across multiple\\nlanguage pairs and domains. Our findings showed\\nthat GPT-4 performs comparably to junior transla-\\ntors in terms of total errors made but lags behind\\nmedium and senior translators. We also notice that'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='tors in terms of total errors made but lags behind\\nmedium and senior translators. We also notice that\\nGPT-4’s translation capability gradually weakens\\nfrom resource-rich to resource-poor language pairs.\\nQualitative analysis revealed that GPT-4 tends to\\nproduce more literal translations compared to hu-\\nman translators but suffers less from imagined in-\\nformation.\\nThe results of this study demonstrate that GPT-4\\nhas made significant strides in approaching human-\\nlevel translation quality, as well as highlighting the\\nnuanced difference between them. This suggests\\npromising opportunities for collaboration and en-\\nhancement of translation workflows. As research\\ncontinues to advance, we anticipate that LLMs will\\nbecome increasingly valuable tools in the trans-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='hancement of translation workflows. As research\\ncontinues to advance, we anticipate that LLMs will\\nbecome increasingly valuable tools in the trans-\\nlation industry, working alongside human transla-\\ntors to improve productivity, efficiency, and overall\\ntranslation quality.\\n7\\nLimitations\\nOur work is limited in the following aspects: (1)\\nWe benchmark GPT-4 for translation tasks, as it is\\na representative large language model and shows\\nstate-of-the-art performance for many text-based\\ntasks. However, our evaluations can be extended\\nto other LLMs such as Claude-3. (2) Our eval-\\nuation covers three languages and six directions\\nfrom resource-rich to resource-poor. However, for\\nother languages, there might be linguistic-specific\\nphenomena that are not covered in this paper.\\nReferences'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='other languages, there might be linguistic-specific\\nphenomena that are not covered in this paper.\\nReferences\\nGuangsheng Bao, Yanbin Zhao, Zhiyang Teng,\\nLinyi Yang, and Yue Zhang. 2023.\\nFast-\\ndetectgpt:\\nEfficient zero-shot detection of\\nmachine-generated text via conditional probabil-\\nity curvature. arXiv preprint arXiv:2310.05130.\\nLjubisa Bojic, Predrag Kovacevic, and Milan\\nCabarkapa. 2023.\\nGpt-4 surpassing human\\nperformance in linguistic pragmatics.\\narXiv\\npreprint arXiv:2312.09545.\\nJacob Cohen. 1960. A coefficient of agreement for\\nnominal scales. Educational and psychological\\nmeasurement, 20(1):37–46.\\nSeamless Communication, Loïc Barrault, Yu-An\\nChung, Mariano Cora Meglioli, David Dale,\\nNing Dong, Paul-Ambroise Duquenne, Hady\\nElsahar, Hongyu Gong, Kevin Heffernan, John'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='Chung, Mariano Cora Meglioli, David Dale,\\nNing Dong, Paul-Ambroise Duquenne, Hady\\nElsahar, Hongyu Gong, Kevin Heffernan, John\\nHoffman, Christopher Klaiber, Pengwei Li,\\nDaniel Licht, Jean Maillard, Alice Rakotoari-\\nson, Kaushik Ram Sadagopan, Guillaume Wen-\\nzek, Ethan Ye, Bapi Akula, Peng-Jen Chen,\\nNaji El Hachem, Brian Ellis, Gabriel Mejia\\nGonzalez, Justin Haaheim, Prangthip Hansanti,\\nRuss Howes, Bernie Huang, Min-Jae Hwang,\\nHirofumi Inaguma, Somya Jain, Elahe Kalbassi,\\nAmanda Kallet, Ilia Kulikov, Janice Lam, Daniel\\nLi, Xutai Ma, Ruslan Mavlyutov, Benjamin Pelo-\\nquin, Mohamed Ramadan, Abinesh Ramakrish-\\nnan, Anna Sun, Kevin Tran, Tuan Tran, Igor\\nTufanov, Vish Vogeti, Carleigh Wood, Yilin\\nYang, Bokai Yu, Pierre Andrews, Can Balioglu,\\nMarta R. Costa-jussà, Onur Celebi, Maha El-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='Tufanov, Vish Vogeti, Carleigh Wood, Yilin\\nYang, Bokai Yu, Pierre Andrews, Can Balioglu,\\nMarta R. Costa-jussà, Onur Celebi, Maha El-\\nbayad, Cynthia Gao, Francisco Guzmán, Justine\\nKao, Ann Lee, Alexandre Mourachko, Juan Pino,\\nSravya Popuri, Christophe Ropers, Safiyyah\\nSaleem, Holger Schwenk, Paden Tomasello,\\nChanghan Wang, Jeff Wang, and Skyler Wang.\\n2023. Seamlessm4t: Massively multilingual &\\nmultimodal machine translation.\\nMaxim Enis and Mark Hopkins. 2024.\\nFrom\\nllm to nmt:\\nAdvancing low-resource ma-\\n\\x0cchine translation with claude. arXiv preprint\\narXiv:2404.13813.\\nAkhbardeh Farhad,\\nArkhangorodsky Arkady,\\nBiesialska Magdalena, Bojar Ondˇrej, Chatterjee\\nRajen, Chaudhary Vishrav, Marta R Costa-jussa,\\nEspaña-Bonet Cristina, Fan Angela, Federmann'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='Biesialska Magdalena, Bojar Ondˇrej, Chatterjee\\nRajen, Chaudhary Vishrav, Marta R Costa-jussa,\\nEspaña-Bonet Cristina, Fan Angela, Federmann\\nChristian, et al. 2021. Findings of the 2021 con-\\nference on machine translation (wmt21). In Pro-\\nceedings of the Sixth Conference on Machine\\nTranslation, pages 1–88. Association for Com-\\nputational Linguistics.\\nZhaopeng Feng, Yan Zhang, Hao Li, Bei Wu, Jiayu\\nLiao, Wenqiang Liu, Jun Lang, Yang Feng, Jian\\nWu, and Zuozhu Liu. 2024. Tear: Improving\\nllm-based machine translation with systematic\\nself-refinement.\\nLukas Fischer and Samuel L¨\"aubli. 2020. What’s\\nthe difference between professional human and\\nmachine translation?\\na blind multi-language\\nstudy on domain-specific MT. In Proceedings\\nof the 22nd Annual Conference of the European'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='machine translation?\\na blind multi-language\\nstudy on domain-specific MT. In Proceedings\\nof the 22nd Annual Conference of the European\\nAssociation for Machine Translation, pages 215–\\n224, Lisboa, Portugal. European Association for\\nMachine Translation.\\nMarkus Freitag, George Foster, David Grang-\\nier, Viresh Ratnakar, Qijun Tan, and Wolfgang\\nMacherey. 2021. Experts, errors, and context:\\nA large-scale study of human evaluation for ma-\\nchine translation. Transactions of the Associ-\\nation for Computational Linguistics, 9:1460–\\n1474.\\nMarkus Freitag, Nitika Mathur, Chi-kiu Lo, Eleft-\\nherios Avramidis, Ricardo Rei, Brian Thompson,\\nTom Kocmi, Frederic Blain, Daniel Deutsch,\\nCraig Stewart, Chrysoula Zerva, Sheila Castilho,\\nAlon Lavie, and George Foster. 2023. Results'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='Tom Kocmi, Frederic Blain, Daniel Deutsch,\\nCraig Stewart, Chrysoula Zerva, Sheila Castilho,\\nAlon Lavie, and George Foster. 2023. Results\\nof WMT23 metrics shared task: Metrics might\\nbe guilty but references are not innocent. In Pro-\\nceedings of the Eighth Conference on Machine\\nTranslation, pages 578–628, Singapore. Associ-\\nation for Computational Linguistics.\\nMarkus Freitag, Ricardo Rei, Nitika Mathur, Chi-\\nkiu Lo, Craig Stewart, Eleftherios Avramidis,\\nTom Kocmi, George Foster, Alon Lavie, and\\nAndré F. T. Martins. 2022. Results of WMT22\\nmetrics shared task: Stop using BLEU – neu-\\nral metrics are better and more robust. In Pro-\\nceedings of the Seventh Conference on Machine\\nTranslation (WMT), pages 46–68, Abu Dhabi,\\nUnited Arab Emirates (Hybrid). Association for\\nComputational Linguistics.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='Translation (WMT), pages 46–68, Abu Dhabi,\\nUnited Arab Emirates (Hybrid). Association for\\nComputational Linguistics.\\nTanya Goyal, Junyi Jessy Li, and Greg Durrett.\\n2022. News summarization and evaluation in the\\nera of gpt-3. arXiv preprint arXiv:2209.12356.\\nYvette Graham, Timothy Baldwin, Alistair Mof-\\nfat, and Justin Zobel. 2013. Continuous mea-\\nsurement scales in human evaluation of machine\\ntranslation. In Proceedings of the 7th Linguis-\\ntic Annotation Workshop and Interoperability\\nwith Discourse, pages 33–41, Sofia, Bulgaria.\\nAssociation for Computational Linguistics.\\nYvette Graham, Christian Federmann, Maria Es-\\nkevich, and Barry Haddow. 2020. Assessing\\nhuman-parity in machine translation on the seg-\\nment level. In Findings of the Association for'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='kevich, and Barry Haddow. 2020. Assessing\\nhuman-parity in machine translation on the seg-\\nment level. In Findings of the Association for\\nComputational Linguistics: EMNLP 2020, pages\\n4199–4207, Online. Association for Computa-\\ntional Linguistics.\\nTianyu Han, Lisa C Adams, Keno Bressem, Fe-\\nlix Busch, Luisa Huck, Sven Nebelung, and\\nDaniel Truhn. 2023. Comparative analysis of\\ngpt-4vision, gpt-4 and open source llms in clin-\\nical diagnostic accuracy: A benchmark against\\nhuman expertise. medRxiv, pages 2023–11.\\nHany Hassan, Anthony Aue, Chang Chen, Vishal\\nChowdhary, Jonathan Clark, Christian Fed-\\nermann, Xuedong Huang, Marcin Junczys-\\nDowmunt, William Lewis, Mu Li, et al. 2018.\\nAchieving human parity on automatic chinese\\nto english news translation.\\narXiv preprint\\narXiv:1803.05567.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='Dowmunt, William Lewis, Mu Li, et al. 2018.\\nAchieving human parity on automatic chinese\\nto english news translation.\\narXiv preprint\\narXiv:1803.05567.\\nDan Hendrycks, Collin Burns, Steven Basart, Andy\\nZou, Mantas Mazeika, Dawn Song, and Jacob\\nSteinhardt. 2021. Measuring massive multitask\\nlanguage understanding.\\nAmr Hendy, Mohamed Abdelrehim, Amr Sharaf,\\nVikas Raunak, Mohamed Gabr, Hitokazu Mat-\\nsushita, Young Jin Kim, Mohamed Afify, and\\nHany Hassan Awadalla. 2023. How good are gpt\\nmodels at machine translation? a comprehensive\\nevaluation. arXiv preprint arXiv:2302.09210.\\nHui Huang, Shuangzhi Wu, Xinnian Liang, Bing\\nWang, Yanrui Shi, Peihao Wu, Muyun Yang, and\\nTiejun Zhao. 2023. Towards making the most of\\n\\x0cllm for translation quality estimation. In CCF'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='Wang, Yanrui Shi, Peihao Wu, Muyun Yang, and\\nTiejun Zhao. 2023. Towards making the most of\\n\\x0cllm for translation quality estimation. In CCF\\nInternational Conference on Natural Language\\nProcessing and Chinese Computing, pages 375–\\n386. Springer.\\nWenxiang Jiao, Wenxuan Wang, Jen tse Huang,\\nXing Wang, Shuming Shi, and Zhaopeng Tu.\\n2023a. Is chatgpt a good translator? yes with\\ngpt-4 as the engine.\\nWenxiang Jiao, Wenxuan Wang, Jen tse Huang,\\nXing Wang, Shuming Shi, and Zhaopeng Tu.\\n2023b. Is chatgpt a good translator? yes with\\ngpt-4 as the engine.\\nAhrii Kim, Yunju Bak, Jimin Sun, Sungwon Lyu,\\nand Changmin Lee. 2023.\\nThe suboptimal\\nwmt test sets and its impact on human parity.\\nPreprints.\\nFilip Klubiˇcka, Antonio Toral, and Víctor M\\nSánchez-Cartagena. 2018.\\nQuantitative fine-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='wmt test sets and its impact on human parity.\\nPreprints.\\nFilip Klubiˇcka, Antonio Toral, and Víctor M\\nSánchez-Cartagena. 2018.\\nQuantitative fine-\\ngrained human evaluation of machine transla-\\ntion systems: a case study on english to croatian.\\nMachine Translation, 32(3):195–215.\\nTom Kocmi, Eleftherios Avramidis, Rachel Baw-\\nden, Ondˇrej Bojar, Anton Dvorkovich, Chris-\\ntian Federmann, Mark Fishel, Markus Freitag,\\nThamme Gowda, Roman Grundkiewicz, et al.\\n2023. Findings of the 2023 conference on ma-\\nchine translation (wmt23): Llms are here but\\nnot quite there yet. In Proceedings of the Eighth\\nConference on Machine Translation, pages 1–42.\\nTom Kocmi, Rachel Bawden, Ondˇrej Bojar, Anton\\nDvorkovich, Christian Federmann, Mark Fishel,\\nThamme Gowda, Yvette Graham, Roman Grund-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='Tom Kocmi, Rachel Bawden, Ondˇrej Bojar, Anton\\nDvorkovich, Christian Federmann, Mark Fishel,\\nThamme Gowda, Yvette Graham, Roman Grund-\\nkiewicz, Barry Haddow, et al. 2022. Findings\\nof the 2022 conference on machine translation\\n(wmt22). In Proceedings of the Seventh Con-\\nference on Machine Translation (WMT), pages\\n1–45.\\nKlaus Krippendorff. 1980. Validity in content anal-\\nysis. Computerstrategien für die Kommunika-\\ntionsanalyse, 69:45p.\\nYafu Li, Qintong Li, Leyang Cui, Wei Bi, Longyue\\nWang, Linyi Yang, Shuming Shi, and Yue Zhang.\\n2023. Deepfake text detection in the wild. arXiv\\npreprint arXiv:2305.13242.\\nPengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao\\nJiang, Hiroaki Hayashi, and Graham Neubig.\\n2023a. Pre-train, prompt, and predict: A sys-\\ntematic survey of prompting methods in natural'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='Jiang, Hiroaki Hayashi, and Graham Neubig.\\n2023a. Pre-train, prompt, and predict: A sys-\\ntematic survey of prompting methods in natural\\nlanguage processing. ACM Computing Surveys,\\n55(9):1–35.\\nZhengliang Liu, Tianyang Zhong, Yiwei Li, Yu-\\ntong Zhang, Yi Pan, Zihao Zhao, Peixin Dong,\\nChao Cao, Yuxiao Liu, Peng Shu, et al. 2023b.\\nEvaluating large language models for radiology\\nnatural language processing.\\narXiv preprint\\narXiv:2307.13693.\\nArle Lommel, Maja Popovic, and Aljoscha Bur-\\nchardt. 2014. Assessing inter-annotator agree-\\nment for translation error annotation. In MTE:\\nWorkshop on Automatic and Manual Metrics for\\nOperational Translation Evaluation, pages 31–\\n37. Language Resources and Evaluation Confer-\\nence Reykjavik.\\nLaurence T Maloney, Maria F Dal Martello, Vi-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='37. Language Resources and Evaluation Confer-\\nence Reykjavik.\\nLaurence T Maloney, Maria F Dal Martello, Vi-\\nvian Fei, and Valerie Ma. 2024.\\nA compar-\\nison of human and gpt-4 use of probabilistic\\nphrases in a coordination game. Scientific re-\\nports, 14(1):6835.\\nHiroki Nakayama, Takahiro Kubo, Junya Ka-\\nmura, Yasufumi Taniguchi, and Xu Liang.\\n2018.\\ndoccano:\\nText\\nannotation\\ntool\\nfor\\nhuman.\\nSoftware\\navailable\\nfrom\\nhttps://github.com/doccano/doccano.\\nHa Nguyen and Vicki Allan. 2024. Using gpt-4\\nto provide tiered, formative code feedback. In\\nProceedings of the 55th ACM Technical Sympo-\\nsium on Computer Science Education V. 1, pages\\n958–964.\\nKeqin Peng, Liang Ding, Qihuang Zhong, Li Shen,\\nXuebo Liu, Min Zhang, Yuanxin Ouyang, and\\nDacheng Tao. 2023. Towards making the most'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='958–964.\\nKeqin Peng, Liang Ding, Qihuang Zhong, Li Shen,\\nXuebo Liu, Min Zhang, Yuanxin Ouyang, and\\nDacheng Tao. 2023. Towards making the most\\nof chatgpt for machine translation. In Findings\\nof the Association for Computational Linguistics:\\nEMNLP 2023, pages 5622–5633.\\nThierry Poibeau. 2022. On\" human parity\" and\" su-\\nper human performance\" in machine translation\\nevaluation. In Language Resource and Evalua-\\ntion Conference.\\nRicardo Rei, Craig Stewart, Ana C Farinha, and\\nAlon Lavie. 2020a. COMET: A neural frame-\\nwork for MT evaluation. In Proceedings of the\\n\\x0c2020 Conference on Empirical Methods in Natu-\\nral Language Processing (EMNLP), pages 2685–\\n2702, Online. Association for Computational\\nLinguistics.\\nRicardo Rei, Craig Stewart, Ana C Farinha, and\\nAlon Lavie. 2020b. Comet: A neural frame-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='2702, Online. Association for Computational\\nLinguistics.\\nRicardo Rei, Craig Stewart, Ana C Farinha, and\\nAlon Lavie. 2020b. Comet: A neural frame-\\nwork for mt evaluation. In Proceedings of the\\n2020 Conference on Empirical Methods in Natu-\\nral Language Processing (EMNLP), pages 2685–\\n2702.\\nSai Cheong Siu. 2023. Chatgpt and gpt-4 for pro-\\nfessional translators: Exploring the potential of\\nlarge language models in translation. Available\\nat SSRN 4448091.\\nAntonio Toral, Sheila Castilho, Ke Hu, and Andy\\nWay. 2018. Attaining the unattainable? reassess-\\ning claims of human parity in neural machine\\ntranslation. In Proceedings of the Third Confer-\\nence on Machine Translation: Research Papers,\\npages 113–123, Brussels, Belgium. Association\\nfor Computational Linguistics.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='ence on Machine Translation: Research Papers,\\npages 113–123, Brussels, Belgium. Association\\nfor Computational Linguistics.\\nLongyue Wang, Chenyang Lyu, Tianbo Ji, Zhirui\\nZhang, Dian Yu, Shuming Shi, and Zhaopeng\\nTu. 2023a. Document-level machine translation\\nwith large language models.\\nWenxuan Wang, Wenxiang Jiao, Jingyuan Huang,\\nRuyi Dai, Jen-tse Huang, Zhaopeng Tu, and\\nMichael R Lyu. 2023b. Not all countries cel-\\nebrate thanksgiving: On the cultural dominance\\nin large language models. CoRR.\\nMinghao Wu, Thuy-Trang Vu, Lizhen Qu, George\\nFoster, and Gholamreza Haffari. 2024a. Adapt-\\ning large language models for document-\\nlevel machine translation.\\narXiv preprint\\narXiv:2401.06468.\\nMinghao Wu, Yulin Yuan, Gholamreza Haffari,\\nand Longyue Wang. 2024b. (perhaps) beyond'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='level machine translation.\\narXiv preprint\\narXiv:2401.06468.\\nMinghao Wu, Yulin Yuan, Gholamreza Haffari,\\nand Longyue Wang. 2024b. (perhaps) beyond\\nhuman translation: Harnessing multi-agent col-\\nlaboration for translating ultra-long literary texts.\\narXiv preprint arXiv:2405.11804.\\nMinghao Wu, Yulin Yuan, Gholamreza Haffari,\\nand Longyue Wang. 2024c. (perhaps) beyond\\nhuman translation: Harnessing multi-agent col-\\nlaboration for translating ultra-long literary texts.\\nHaoran Xu, Young Jin Kim, Amr Sharaf, and\\nHany Hassan Awadalla. 2023. A paradigm shift\\nin machine translation: Boosting translation per-\\nformance of large language models.\\nLiang Xu, Hai Hu, Xuanwei Zhang, Lu Li, Chen-\\njie Cao, Yudong Li, Yechen Xu, Kai Sun, Dian\\nYu, Cong Yu, et al. 2020.\\nClue: A chinese'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='Liang Xu, Hai Hu, Xuanwei Zhang, Lu Li, Chen-\\njie Cao, Yudong Li, Yechen Xu, Kai Sun, Dian\\nYu, Cong Yu, et al. 2020.\\nClue: A chinese\\nlanguage understanding evaluation benchmark.\\narXiv preprint arXiv:2004.05986.\\nFanghua Ye, Mingming Yang, Jianhui Pang,\\nLongyue Wang, Derek F. Wong, Emine Yilmaz,\\nShuming Shi, and Zhaopeng Tu. 2024. Bench-\\nmarking llms via uncertainty quantification.\\nLifan Yuan, Yangyi Chen, Ganqu Cui, Hongcheng\\nGao, Fangyuan Zou, Xingyi Cheng, Heng Ji,\\nZhiyuan Liu, and Maosong Sun. 2023. Revisit-\\ning out-of-distribution robustness in nlp: Bench-\\nmark, analysis, and llms evaluations.\\nYue Zhang, Yafu Li, Leyang Cui, Deng Cai, Lemao\\nLiu, Tingchen Fu, Xinting Huang, Enbo Zhao,\\nYu Zhang, Yulong Chen, et al. 2023. Siren’s\\nsong in the ai ocean: a survey on hallucina-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='Liu, Tingchen Fu, Xinting Huang, Enbo Zhao,\\nYu Zhang, Yulong Chen, et al. 2023. Siren’s\\nsong in the ai ocean: a survey on hallucina-\\ntion in large language models. arXiv preprint\\narXiv:2309.01219.\\nZihao Zhao, Eric Wallace, Shi Feng, Dan Klein,\\nand Sameer Singh. 2021. Calibrate before use:\\nImproving few-shot performance of language\\nmodels. In International conference on machine\\nlearning, pages 12697–12706. PMLR.\\nJie Zhu, Junhui Li, Yalong Wen, and Lifan Guo.\\n2024.\\nBenchmarking large language models\\non cflue–a chinese financial language under-\\nstanding evaluation dataset.\\narXiv preprint\\narXiv:2405.10542.\\nA\\nExpertise of Human Annotators\\nTo categorize translators into junior, medium, or\\nsenior levels, we have established a comprehensive\\nset of criteria that take into account various factors'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='senior levels, we have established a comprehensive\\nset of criteria that take into account various factors\\nindicative of a translator’s expertise and experience.\\nThese factors include the translator’s educational\\nbackground, particularly the prestige of the insti-\\ntution from which they graduated, as well as their\\nlength of service in the translation industry, the\\nduration of their translation career, the number of\\ntranslations completed, and any professional certifi-\\ncations they have obtained. To ensure the ongoing\\ncompetence of our translators, we conduct quar-\\nterly assessments to evaluate their performance.\\n\\x0cFor instance, to be classified as a senior-level trans-\\nlator, an individual must possess a minimum of\\nten years of translation experience, demonstrate'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='lator, an individual must possess a minimum of\\nten years of translation experience, demonstrate\\nexceptional proficiency by achieving a score of\\n99% on our assessments, and hold the distinguished\\nCATTI++ translation certification. By considering\\nthese stringent criteria, we aim to maintain a highly\\nqualified and skilled pool of translators across all\\nlevels of expertise.\\nB\\nAnnotation Requirements\\nB.1\\nError Types\\nOur annotation system is built upon the open-\\nsourced doccano system 3. In Figure 5, we provide\\na screenshot of our annotation system. For each\\nsource sentence, outputs for different systems are\\ngiven and the annotators can select spans of the text\\nand annotate the error type and severity.\\nC\\nDetailed Explanation and Guidance for\\nEach Error Types'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='and annotate the error type and severity.\\nC\\nDetailed Explanation and Guidance for\\nEach Error Types\\nOur evaluation protocol largely follows the MQM\\ncriteria released by Unbabel4. We provide a de-\\ntailed annotation manual for annotators, including\\nan explanation for each error type as well as illus-\\ntrative examples for error types. It is included in\\nthe following:\\nC.1\\nAnnotation Requirements\\nThe minimum unit that can be selected and anno-\\ntated is a whole word, a whitespace, a punctuation\\nmark, or an isolated character. In the following\\nexample, the version in French has an extra excla-\\nmation mark, so it’s necessary to annotate it as a\\nPunctuation error:\\n[EN] Thank you very much.\\n[FR] Merci beaucoup!\\nWrong\\nselection\\n→Merci\\n[beau-\\ncoup!]PUNCTUATION\\nCorrect\\nselection\\n→Merci\\nbeau-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='Punctuation error:\\n[EN] Thank you very much.\\n[FR] Merci beaucoup!\\nWrong\\nselection\\n→Merci\\n[beau-\\ncoup!]PUNCTUATION\\nCorrect\\nselection\\n→Merci\\nbeau-\\ncoup[!]PUNCTUATION\\nIf the issue occurs in a multiword expression,\\nyou will need to select the whole expression; if, for\\nexample, an entire sentence was translated and it\\nshouldn’t have been, you should select the entire\\nsentence.\\n3https://github.com/doccano/doccano\\n4\\nIn the following example, we have an Unnatural\\nFlow error:\\n[EN] Hi, Mary here.\\n[ES] Hola, Mary aquí.\\nWrong\\nselection\\n→\\nHola,\\n[Mary\\naquí.]UNNATURAL FLOW\\nCorrect\\nselection\\n→\\nHola,\\n[Mary\\naquí]UNNATURAL FLOW.\\nC.2\\nError Types\\nAccuracy\\n• Mistranslation\\n– Description: Translation does not accu-\\nrately represent the source.\\n– Example:\\n[EN] It has to be done by the book.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='Accuracy\\n• Mistranslation\\n– Description: Translation does not accu-\\nrately represent the source.\\n– Example:\\n[EN] It has to be done by the book.\\n[FR] Il doit être fait [par le\\nlivre]MISTRANSLATION\\n[Reason] The word-for-word trans-\\nlation into French doesn’t work.\\n• Addition\\n– Description: Information not present in\\nthe source.\\n– Example:\\n[EN] That way you can be sure that\\nyou were the one who made the\\nchanges.\\n[ES] Así puedes estar seguro de que\\nfuiste tú quien hizo [todos ADDI-\\ntIoN los cambios.\\n[Reason] [Todos] (meaning ’all’ in\\nSpanish) is not present in the source\\nand it is incorrectly added in the\\ntarget text.\\n• MT Hallucination\\n– Description: information that has noth-\\ning related to source; or gibberish; or\\nrepeats\\n– Example:\\n[EN] You can send us a follow-up'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='– Description: information that has noth-\\ning related to source; or gibberish; or\\nrepeats\\n– Example:\\n[EN] You can send us a follow-up\\nemail at this address [EMAIL].\\n[ES] [Hágame saber si tiene al-\\nguna otra pregunta]MT HALLUCI-\\nNATION.]\\n[Reason]: The Spanish translation\\n\\x0cFigure 5: A screenshot of the Doccano annotation system we use.\\nreads please let me know if you\\nhave any other questions and it’s\\ngrammatically correct and fluent,\\nbut it has no relation at all with the\\nsource.]\\n• Omission\\n– Description: Missing content from the\\nsource.\\n– Example:\\n[EN] We do not have much informa-\\ntion on this.\\n[FR]\\nNous\\nne\\ndisposons\\npas\\n[]\\nOMISSION\\nbeaucoup\\nd’informations à ce sujet.\\n[Reason]:\\nThe French sentence\\nrequires the preposition [de] (dis-\\nposer de).\\n• Untranslated\\n– Description: Not translated.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='d’informations à ce sujet.\\n[Reason]:\\nThe French sentence\\nrequires the preposition [de] (dis-\\nposer de).\\n• Untranslated\\n– Description: Not translated.\\n– Example:\\n[EN] How To Make Pizza Dough\\n[FR] Comment faire de [Pizza\\nDough|UNTRANSLATED\\n[Reason]: [Pizza Dough] is not a\\nnamed entity and is untranslated in\\nthe French version.\\n• Wrong Name Entity & Term\\n– Description: Wrong usage of NE and\\nTerminology.\\n– Example:\\n[EN] Dear Wiley,\\n[IT]\\nGentile\\n[Wilar\\nWRONG\\nNAMED ENTITY,\\n[Reason]: The name in the Italian\\nversion doesn’t match the original.\\nFluency\\n• Grammar\\n– Description: Problems with grammar of\\ntarget language.\\n– Example:\\n[EN] I understand that you want to\\ncheck in online.\\n[CS]\\nchàpu,\\nze\\nse\\nchcete\\n[odbavení]gRAMMaR online.\\n[Reason]: Wrong part of speech\\nmakes the sentence ungrammatical'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='check in online.\\n[CS]\\nchàpu,\\nze\\nse\\nchcete\\n[odbavení]gRAMMaR online.\\n[Reason]: Wrong part of speech\\nmakes the sentence ungrammatical\\nin Czech.\\n• Punctuation\\n– Description: incorrect punctuation (for\\nlocale or style).\\n– Example:'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='<img alt=\"Technology.Zh_En.Annotation-2\\nEN\\nProjects\\nStart Annotation\\nY\\n目\\n圃\\n1 of4001&lt;\\n&gt;\\nI&lt;\\nHome\\n原文：\\nProgress\\nDataset\\n如果轮胎气压低，就会显示此警告信息。车辆上的对应轮胎位置指示灯亮。详细信息请参考第8章的“轮胎气压监测系统（TPMS)&quot;部分。\\nTotal\\n400\\nLabels\\nComplete\\n133\\n译文1:lIf thetirepressure is low,thiswarningmessagewillbe displayed.Thecorresponding tireposition indicatorlight on thevehicle\\nMembers\\n·Wrong Name E...\\n34%\\n日\\nComments\\nwillilluminate.Fordetailed information,pleasereferto the&quot;TirePressure MonitoringSystem(TPMs)&quot;section inChapter8.\\nLabel Types\\nGuideline\\n译文2:lf the tire pressure is low,this warningmessage will be displayed.The corresponding tire position indicator light on the vehicle is\\n山\\nMetrics\\n·Wrong Name E...\\nMistranslation (Minor)\\nPunctuation (Minor)\\nSpelling (Minor)\\nSettings'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='山\\nMetrics\\n·Wrong Name E...\\nMistranslation (Minor)\\nPunctuation (Minor)\\nSpelling (Minor)\\nSettings\\nWrong Name Entity&amp; Term (Minor)\\non.Formoreinformation,seethetirepressuremonitoringsystem（TPMS)sectioninChapter8.\\n·Spelling (Mi...\\nOmission (Minor)\\nInconsistent Style(Minor)\\n·Punctuation ...\\nUnnatural Flow\\nOmission (Major)\\nGrammar (Minor)\\n译文3: In case of low tire pressure,this warning message will pop up and the indicator corresponding to the tire willbe on.See&quot;Tire\\nWrongNameEntity&amp;Term(Major)\\nMistranslation (Major)\\nRegister (Minor)\\nPressureMonitoringSystem(TPMS)&quot;SectioninChapter8fordetails.\\n·Spelling (Mi...\\nGrammar (Major)\\nRegister (Major)\\nMT Hallucination (Major)\\nPunctuation (Major)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='·Spelling (Mi...\\nGrammar (Major)\\nRegister (Major)\\nMT Hallucination (Major)\\nPunctuation (Major)\\n译文 4:If the tire pressure is low,a warning message willbe displayed, and the corresponding tire position indicator on the vehicle will\\n·Wrong Name E...\\nMT Hallucination (Minor)\\nUntraslated (Minor)\\nInconsistent Style (Major)\\nSpelling (Major)\\nAddition (Major)\\nAddition (Minor)\\n译文5: lf the tire pressure is low,this warning message willbe displayed, and the corresponding tire indicator on the vehicle will light up.\\nUntrasnalted (Major)\\nNon-translation\\nPleasereferto&quot;TirePressureMonitoringSystem(TPMs)&quot;inChapter8fordetails.\\nKey\\nValue\\nP!\\n2001\\nComments src=\"#\" />\\n\\x0c[EN] Original copy of the Proof of\\nPurchase or Invoice (not a screen-\\nshot):\\n[PT] C’opia original do com-\\nprovante\\nde\\ncompra\\nou\\nnota'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='[EN] Original copy of the Proof of\\nPurchase or Invoice (not a screen-\\nshot):\\n[PT] C’opia original do com-\\nprovante\\nde\\ncompra\\nou\\nnota\\nfiscal\\n(não\\numa\\ncaptura\\nde\\ntela)[.]PUNCTUATION\\n[Reason]: There’s a period instead\\nof a colon in the Brazilian Por-\\ntuguese version of this sentence.\\n• Spelling\\n– Description: incorrect spelling or capital-\\nization.\\n– Example:\\n[EN] This sort of damage is not cov-\\nered under the warranty, but we will\\nseek assistance from a higher sup-\\nport and see what we can do regard-\\ning this issue.\\n[IT] Questo tipo di danno non è cop-\\nerto dalla garanzia, ma chiederò\\ncomunque aiuto ai responsabili\\ndell’assistenza per capire che cosa\\n[Zi]SPELLING può fare per quanto\\nriguarda questo problema.\\n[Reason]: There’s a typo in the\\nsentence in Italian: the word [zi]'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='[Zi]SPELLING può fare per quanto\\nriguarda questo problema.\\n[Reason]: There’s a typo in the\\nsentence in Italian: the word [zi]\\nshould be [si] instead.\\n• Register\\n– Description: Wrong grammatical regis-\\nter (e.g., inappropriately informal pro-\\nnouns).\\n– Example:\\n[EN] Wishing you a great day\\nahead.\\n[DE]\\nIch\\nwünsche\\n[Ih-\\nnen]REGISTER\\neinen\\nschönen\\nTag.\\n[Reason]: The required register for\\nthe German translation is Informal\\nbut the pronoun [Inhen] is Formal.\\n• Inconsistent Style\\n– Description: internal inconsistency (not\\nrelated to terminology).\\n– Example:\\n[EN] Please click on this link. [...]\\nThis link will expire in 24 hours.\\n[NN]\\nKlikk\\npå\\ndenne\\n[lenken].[...]Denne\\n[linken]INCONSISTENCY\\nut-\\nloper om 24 timer.\\n[Reason]: Both [lenk] and [link]\\nare correct in Norwegian, but in the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='Klikk\\npå\\ndenne\\n[lenken].[...]Denne\\n[linken]INCONSISTENCY\\nut-\\nloper om 24 timer.\\n[Reason]: Both [lenk] and [link]\\nare correct in Norwegian, but in the\\nsame document, only one should be\\nused. Note: this is a single error,\\nnot two\\n• Unnatural Flow\\n– Description: translations that are too lit-\\neral or sound unnatural.\\n– Example:\\n[EN] Zebras are ideal for animal\\nmatching.\\n[DE]\\n[Zebras\\nsind\\nideal,\\num\\nbestimmte\\nTiere\\nzu\\nfinden]UNNATURAL FLOW.\\n[Reason] The German translation\\nsounds too literal, it reads like a\\ntranslation, using the verb [finden]\\n(finding) as a translation for match-\\ning. The verb matching should be\\ntranslated as [detektieren] (detect)\\nto read as if it was originally written\\nin the target language: [Zebras sind\\nein ideales Beispiel zur Detektion\\nvon Wildtieren.]\\nOther'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='to read as if it was originally written\\nin the target language: [Zebras sind\\nein ideales Beispiel zur Detektion\\nvon Wildtieren.]\\nOther\\n• Non-translation\\nD\\nExtra Details\\nD.1\\nTranslation Prompt in Preliminary Study\\nIn two experiments, the translation prompt we use\\nis as follows:\\n• Please translate the following sentences from\\n<SRC_LANG> to <TGT_LANG>. Ensure\\nline alignment across the document while\\nmaintaining the fluency of overall translation.\\nThe prompt asks GPT4 to maintain the sentence\\nalignment of the given document, so each sentence\\ncan be aligned back to its source sentence while be-\\ning translated at the document level. In practice, we\\nfind most times GPT4 can follow our instructions.\\n\\x0cOccasionally, it fails to keep the sentence structure'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-07-08T00:23:43+00:00', 'source': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'file_path': '/Users/arunekambaram/Desktop/RAG-ChatBot/data/GPT-4_VS_Human_translators (1).pdf', 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-08T00:23:43+00:00', 'trapped': '', 'modDate': 'D:20240708002343Z', 'creationDate': 'D:20240708002343Z'}, page_content='find most times GPT4 can follow our instructions.\\n\\x0cOccasionally, it fails to keep the sentence structure\\nof the document and merges some sentences in one\\nrow. In these cases, we manually split the merged\\nsentences.\\nD.2\\nModel and Decoding\\nFor GPT-4, we use greedy search for decoding,\\nto ensure the reproducibility of the results. For\\nSeamlessM4T, we use the 2.3B version of seam-\\nlessM4T_v2_large and adopt beam search with\\nbeam size 5.')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks = spiltter.split_documents([docs[0]])\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-4.1.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /Users/arunekambaram/code/venv/lib/python3.12/site-packages (from sentence-transformers) (4.41.2)\n",
      "Requirement already satisfied: tqdm in /Users/arunekambaram/code/venv/lib/python3.12/site-packages (from sentence-transformers) (4.66.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/arunekambaram/code/venv/lib/python3.12/site-packages (from sentence-transformers) (2.3.1)\n",
      "Requirement already satisfied: scikit-learn in /Users/arunekambaram/code/venv/lib/python3.12/site-packages (from sentence-transformers) (1.5.0)\n",
      "Requirement already satisfied: scipy in /Users/arunekambaram/code/venv/lib/python3.12/site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /Users/arunekambaram/code/venv/lib/python3.12/site-packages (from sentence-transformers) (0.23.4)\n",
      "Requirement already satisfied: Pillow in /Users/arunekambaram/code/venv/lib/python3.12/site-packages (from sentence-transformers) (10.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /Users/arunekambaram/code/venv/lib/python3.12/site-packages (from sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: filelock in /Users/arunekambaram/code/venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/arunekambaram/code/venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/arunekambaram/code/venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/arunekambaram/code/venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in /Users/arunekambaram/code/venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: sympy in /Users/arunekambaram/code/venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.12.1)\n",
      "Requirement already satisfied: networkx in /Users/arunekambaram/code/venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/arunekambaram/code/venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/arunekambaram/code/venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/arunekambaram/code/venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.5.15)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Users/arunekambaram/code/venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/arunekambaram/code/venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/arunekambaram/code/venv/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/arunekambaram/code/venv/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/arunekambaram/code/venv/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/arunekambaram/code/venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/arunekambaram/code/venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/arunekambaram/code/venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/arunekambaram/code/venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.6.2)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /Users/arunekambaram/code/venv/lib/python3.12/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Downloading sentence_transformers-4.1.0-py3-none-any.whl (345 kB)\n",
      "Installing collected packages: sentence-transformers\n",
      "Successfully installed sentence-transformers-4.1.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arunekambaram/code/venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_retriever(chunks: List[Document]):\n",
    "    embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "    vectorstore = FAISS.from_documents(chunks, embedding_model)\n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 4})\n",
    "\n",
    "\n",
    "    bm25_retriever = BM25Retriever.from_documents(chunks)\n",
    "    bm25_retriever.k = 4\n",
    "\n",
    "    \n",
    "    hybrid_retriever = EnsembleRetriever(\n",
    "        retrievers=[retriever, bm25_retriever],\n",
    "        weights=[0.5, 0.5]  \n",
    "    )\n",
    "\n",
    "    return hybrid_retriever\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
